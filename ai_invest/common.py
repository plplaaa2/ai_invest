
import json
import os
import re
import requests
import time
import math
import feedparser
from datetime import datetime, timedelta, date, timezone
from bs4 import BeautifulSoup
from pykrx import stock


KST = timezone(timedelta(hours=9))

def get_now_kst():
    """í˜„ì¬ í•œêµ­ ì‹œê°„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return datetime.now(KST)

# --- [0. ì‹œìŠ¤í…œ ê³µí†µ ê²½ë¡œ ì„¤ì •] ---
OPTIONS_PATH = "/data/options.json"
BASE_PATH = "/share/ai_analyst"
CONFIG_PATH = os.path.join(BASE_PATH, "rss_config.json")
PENDING_PATH = os.path.join(BASE_PATH, "pending")
REPORT_DIR = os.path.join(BASE_PATH, "reports")

def load_addon_config():
    if os.path.exists(OPTIONS_PATH):
        try:
            with open(OPTIONS_PATH, "r", encoding='utf-8') as f:
                return json.load(f)
        except: pass
    return {}

config = load_addon_config() 


# í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ë¡œì§
openai_key = config.get("openai_api_key", "")
gemini_key = config.get("gemini_api_key", "")
headers = {"Content-Type": "application/json"}

# ğŸ¯ 2. Cloud LLM ëª¨ë“œ íŒì • ë¡œì§ ë³´ì™„
if openai_key or gemini_key:
    if openai_key:
        headers["Authorization"] = f"Bearer {openai_key}"
    print(f"ğŸš€ Cloud LLM ëª¨ë“œë¡œ ì‘ë™í•©ë‹ˆë‹¤. (OpenAI: {'OK' if openai_key else 'NO'}, Gemini: {'OK' if gemini_key else 'NO'})")
else:
    print("ğŸ  Local LLM ëª¨ë“œë¡œ ì‘ë™í•©ë‹ˆë‹¤ (API í‚¤ ì—†ìŒ).")
        

# --- [3. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜] ---
def safe_float(v):
    if v is None or v == "" or v == "-": return 0.0
    try:
        clean_v = re.sub(r'[^\d.-]', '', str(v))
        return float(clean_v) if clean_v else 0.0
    except: return 0.0

def save_to_influx(symbol, data, current_time):
    point = Point("financial_metrics").tag("symbol", symbol)
    for f, v in data.items(): point.field(f, float(v))
    point.time(current_time)
    if write_api:
        try:
            write_api.write(bucket=INFLUX_BUCKET, org=INFLUX_ORG, record=point)
            return True
        except Exception as e:
            print(f"âš ï¸ InfluxDB ì“°ê¸° ì—ëŸ¬ ({symbol}): {e}")
    return False
    
def save_report_to_file(content, section_name):
    # 1. ê²½ë¡œ ì„¤ì • ë° í´ë” ì„¸ë¶„í™”
    base_dir = REPORT_DIR
    dir_map = {
        'daily': '01_daily', 'weekly': '02_weekly', 
        'monthly': '03_monthly', 'yearly': '04_yearly'
    }
    # section_nameì´ ë§µì— ì—†ìœ¼ë©´ ê¸°ë³¸ í´ë” ì‚¬ìš©
    subdir = dir_map.get(section_name.lower(), "05_etc")
    report_dir = os.path.join(base_dir, subdir)
    os.makedirs(report_dir, exist_ok=True)
    
    # 2. íŒŒì¼ëª… ìƒì„± ë° ì €ì¥ (ê¸°ë¡ìš©)
    timestamp = datetime.now().strftime("%Y-%m-%d_%H%M")
    filename = f"{timestamp}_{section_name.replace(' ', '_')}.txt"
    filepath = os.path.join(report_dir, filename)
    
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(content)

    # 3. ğŸ¯ AI ì°¸ì¡°ìš© Latest íŒŒì¼ ê°±ì‹  (ê³ ì • ê²½ë¡œ)
    latest_path = os.path.join(report_dir, "latest.txt")
    with open(latest_path, "w", encoding="utf-8") as f:
        f.write(content)

    # 4. ğŸ§¹ ê³„ì¸µí˜• ìë™ ì •ì œ (Purge) ë¡œì§
    # ê·œì¹™: Daily(7ì¼), Weekly(30ì¼), Monthly(365ì¼) ë³´ê´€
    purge_rules = {'01_daily': 9, '02_weekly': 35, '03_monthly': 370}
    if subdir in purge_rules:
        limit_days = purge_rules[subdir]
        threshold = time.time() - (limit_days * 86400)
        for f in os.listdir(report_dir):
            if f == "latest.txt": continue # ìµœì‹  ë§¥ë½ì€ ë³´í˜¸
            f_p = os.path.join(report_dir, f)
            if os.path.isfile(f_p) and os.path.getmtime(f_p) < threshold:
                os.remove(f_p)
                
    return filepath
    
def load_historical_contexts():
    """íŒŒì¼ì´ ì—†ì–´ë„ ì—ëŸ¬ ì—†ì´ ì‘ë™í•˜ë©°, AIì—ê²Œ í˜„ì¬ ìƒí™©ì„ ì„¤ëª…í•©ë‹ˆë‹¤."""
    base_dir = REPORT_DIR
    dir_map = {
        'YEARLY_STRATEGY': '04_yearly/latest.txt',
        'MONTHLY_THEME': '03_monthly/latest.txt',
        'WEEKLY_MOMENTUM': '02_weekly/latest.txt',
        'DAILY_LOG': '01_daily/latest.txt'
    }
    
    context_text = "### [ ì—­ì‚¬ì  ë§¥ë½ ì°¸ì¡° ë°ì´í„° ]\n"
    
    for label, rel_path in dir_map.items():
        full_path = os.path.join(base_dir, rel_path)
        
        # ğŸ›¡ï¸ íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ ì²´í¬
        if os.path.exists(full_path):
            with open(full_path, "r", encoding="utf-8") as f:
                content = f.read()
                # ë°ì´í„°ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ê¸°ë¡ì´ ì—†ëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼
                if len(content.strip()) > 10:
                    context_text += f"\n<{label}>\n{content[:1000]}\n"
                else:
                    context_text += f"\n<{label}>: í•´ë‹¹ ì£¼ê¸°ì˜ ë¶„ì„ ë°ì´í„°ê°€ ì•„ì§ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.\n"
        else:
            # ğŸ’¡ íŒŒì¼ì´ ì—†ì„ ë•Œ AIì—ê²Œ ì¤„ ë©”ì‹œì§€
            # AIê°€ "ê³¼ê±° ë°ì´í„°ê°€ ì—†ìœ¼ë‹ˆ ì˜¤ëŠ˜ ìˆ˜ì¹˜ì— ë” ì§‘ì¤‘í•´ì„œ ë¶„ì„í•´ë¼"ë¼ê³  íŒë‹¨í•˜ê²Œ ìœ ë„í•©ë‹ˆë‹¤.
            context_text += f"\n<{label}>: ì‹œìŠ¤í…œ ë„ì… ì´ˆê¸° ë‹¨ê³„ë¡œ, ì•„ì§ {label} ë°ì´í„°ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜„ì¬ ê°€ìš©í•œ ìµœì‹  ë°ì´í„° ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„í•˜ì‹­ì‹œì˜¤.\n"
            
    return context_text
    
def load_data():
    """ì„œë¹„ìŠ¤ ì„¤ì •(RSS, AI ëª¨ë¸ ë“±)ì„ ë¡œë“œí•˜ê³  ë¯¸ì¡´ì¬ ì‹œ ê¸°ë³¸ ì„¤ì •ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    default_structure = {
        "feeds": [], 
        "update_interval": 10, 
        "view_range": "ì‹¤ì‹œê°„", 
        "retention_days": 7,
        "report_news_count": 100, 
        "report_auto_gen": True, 
        "report_gen_time": "08:00", 
        "report_days": 3,
        
        # ğŸ¯ ë‰´ìŠ¤ íŒë… ëª¨ë¸ ì„¤ì • (Filter)
        "filter_model": {
            "provider": "Local",
            "name": "openai/gpt-oss-20b",
            "url": "http://192.168.1.105:11434/v1",
            "key": "",
            "temperature": 0.1,  # ğŸ’¡ íŒë…ì€ ì¼ê´€ì„±ì´ ì¤‘ìš”í•˜ë¯€ë¡œ ë‚®ê²Œ ì„¤ì •
            "prompt": "íˆ¬ì ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‰´ìŠ¤ê°€ ê±°ì‹œê²½ì œë‚˜ ìœ ë™ì„±ì— ì¤‘ìš”í•œì§€ íŒë…í•˜ì—¬ 0~5ì ì„ ë§¤ê¸°ì„¸ìš”."
        },
        
        # ğŸ›ï¸ íˆ¬ì ë³´ê³ ì„œ ëª¨ë¸ ì„¤ì • (Analyst)
        "analyst_model": {
            "provider": "Local",
            "name": "openai/gpt-oss-20b",
            "url": "http://192.168.1.105:11434/v1",
            "key": "",
            "temperature": 0.3,  # ğŸ’¡ ë³´ê³ ì„œëŠ” ì•½ê°„ì˜ í†µì°°ë ¥ì´ í•„ìš”í•˜ë¯€ë¡œ 0.3~0.5 ê¶Œì¥
            "prompt": "ë‹¹ì‹ ì€ ì „ë¬¸ íˆ¬ì ì „ëµê°€ì…ë‹ˆë‹¤. ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ì—¬ íˆ¬ì ì „ëµì„ ì œì‹œí•˜ì„¸ìš”."
        }
    }
    
    # 1. íŒŒì¼ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ì„¤ì • ìƒì„± (ìë™ ë³µêµ¬)
    if not os.path.exists(CONFIG_PATH):
        try:
            os.makedirs(os.path.dirname(CONFIG_PATH), exist_ok=True)
            with open(CONFIG_PATH, "w", encoding="utf-8") as f:
                json.dump(default_structure, f, indent=4, ensure_ascii=False)
            print(f"âœ… ê¸°ë³¸ ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ: {CONFIG_PATH}")
            return default_structure
        except:
            return default_structure

    # 2. íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ ë° ëˆ„ë½ëœ í‚¤ ë³´ì •
    try:
        with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
            loaded = json.load(f)
            # ìƒˆë¡œìš´ ê¸°ëŠ¥(ì˜¨ë„ ë“±)ì´ ì¶”ê°€ë˜ì–´ í‚¤ê°€ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ê¸°ë³¸ê°’ ë³‘í•©
            for key, val in default_structure.items():
                if key not in loaded: 
                    loaded[key] = val
                elif isinstance(val, dict): # ì¤‘ì²©ëœ ë”•ì…”ë„ˆë¦¬(ëª¨ë¸ ì„¤ì •) ë‚´ë¶€ í‚¤ ë³´ì •
                    for sub_key, sub_val in val.items():
                        if sub_key not in loaded[key]:
                            loaded[key][sub_key] = sub_val
            return loaded
    except:
        return default_structure

# ê³µí†µ ë°ì´í„° ê°ì²´ (ëª¨ë“  ëª¨ë“ˆì—ì„œ ê³µìœ )
data = load_data()

from pykrx import stock

def get_latest_trading_date():
    """ê°€ì¥ ìµœê·¼ ì˜ì—…ì¼ì„ ì•ˆì „í•˜ê²Œ íƒìƒ‰ (ê¸°ì¡´ í•¨ìˆ˜ ì˜í–¥ ì—†ìŒ)"""
    try:
        now = get_now_kst()
        # ìµœê·¼ 10ì¼ì¹˜ ë°ì´í„°ë¥¼ ê¸ì–´ ë§ˆì§€ë§‰ ì¸ë±ìŠ¤(ì˜ì—…ì¼) ì¶”ì¶œ
        df = stock.get_index_ohlcv_by_date((now - timedelta(days=10)).strftime("%Y%m%d"), now.strftime("%Y%m%d"), "1001")
        return df.index[-1].strftime("%Y%m%d")
    except:
        return get_now_kst().strftime("%Y%m%d")

def get_krx_market_indicators():
    """ì½”ìŠ¤í”¼/ì½”ìŠ¤ë‹¥ ì§€ìˆ˜, ê±°ë˜ì •ë³´, ìˆ˜ê¸‰í˜„í™©ì„ ì–µ ì› ë‹¨ìœ„ë¡œ ìš”ì•½"""
    try:
        target_date = get_latest_trading_date()
        summary = f"### [ KRX ì‹œì¥ ì§€í‘œ ìš”ì•½ ({target_date}) ]\n"

        # 1. ì§€ìˆ˜ ë° ê±°ë˜ ë°ì´í„° (ì–µ ì› ë‹¨ìœ„ í™˜ì‚°)
        for m_name, m_code in [("KOSPI", "1001"), ("KOSDAQ", "2001")]:
            df = stock.get_index_ohlcv_by_date(target_date, target_date, m_code)
            if not df.empty:
                row = df.iloc[0]
                amount_bill = row['ê±°ë˜ëŒ€ê¸ˆ'] / 100_000_000 # ì–µ ì› ë‹¨ìœ„
                summary += f"- {m_name}: {row['ì¢…ê°€']:,.2f} (ê±°ë˜ëŸ‰: {row['ê±°ë˜ëŸ‰']:,.0f}, ê±°ë˜ëŒ€ê¸ˆ: {amount_bill:,.0f}ì–µ)\n"

        # 2. íˆ¬ììë³„ ìˆœë§¤ìˆ˜ í•©ê³„
        df_inv = stock.get_market_net_purchase_of_equities_by_ticker(target_date, target_date, "ALL")
        foreign_bill = df_inv['ì™¸êµ­ì¸'].sum() / 100_000_000
        inst_bill = df_inv['ê¸°ê´€í•©ê³„'].sum() / 100_000_000
        summary += f"- íˆ¬ìì ìˆ˜ê¸‰: ì™¸êµ­ì¸ {foreign_bill:,.0f}ì–µ, ê¸°ê´€ {inst_bill:,.0f}ì–µ (ìˆœë§¤ìˆ˜ ê¸°ì¤€)\n"
        
        return summary
    except: return "âš ï¸ KRX ì§€ìˆ˜ ìš”ì•½ ë¡œë“œ ì‹¤íŒ¨"

def get_krx_top_investors():
    """ì™¸êµ­ì¸/ê¸°ê´€ ìˆœë§¤ìˆ˜ ìƒìœ„ 10ê°œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ìƒì„±"""
    try:
        target_date = get_latest_trading_date()
        df = stock.get_market_net_purchase_of_equities_by_ticker(target_date, target_date, "ALL")
        
        def get_top_list(data, col):
            top_df = data.sort_values(by=col, ascending=False).head(10)
            items = []
            for ticker, row in top_df.iterrows():
                name = stock.get_market_ticker_name(ticker)
                val_bill = row[col] / 100_000_000
                items.append(f"{name}({val_bill:,.0f}ì–µ)")
            return ", ".join(items)

        report = "### [ ìˆ˜ê¸‰ ìƒìœ„ ì¢…ëª© (Top 10) ]\n"
        report += f"- ì™¸êµ­ì¸ ë§¤ìˆ˜: {get_top_list(df, 'ì™¸êµ­ì¸')}\n"
        report += f"- ê¸°ê´€ ë§¤ìˆ˜: {get_top_list(df, 'ê¸°ê´€í•©ê³„')}\n"
        return report
    except: return "âš ï¸ ìˆ˜ê¸‰ ì¢…ëª© ë¡œë“œ ì‹¤íŒ¨"

def get_krx_sector_indices():
    """ë°˜ë„ì²´, IT ë“± ì£¼ìš” ì‚°ì—…ë³„ ì§€ìˆ˜ í˜„í™© ì¶”ì¶œ"""
    try:
        target_date = get_latest_trading_date()
        indices = stock.get_index_ticker_list(target_date, market="KRX")
        
        report = "### [ ì£¼ìš” ì‚°ì—…ë³„ ì§€ìˆ˜ í˜„í™© ]\n"
        count = 0
        for ticker in indices:
            name = stock.get_index_ticker_name(ticker)
            if any(kw in name for kw in ['ë°˜ë„ì²´', 'IT', 'ê¸ˆìœµ', 'ì—ë„ˆì§€', 'ë°”ì´ì˜¤', 'ìë™ì°¨']):
                df = stock.get_index_ohlcv_by_date(target_date, target_date, ticker)
                if not df.empty:
                    report += f"- {name}: {df.iloc[0]['ì¢…ê°€']:,.2f}\n"
                    count += 1
            if count >= 8: break
        return report
    except: return "âš ï¸ ì‚°ì—… ì§€ìˆ˜ ë¡œë“œ ì‹¤íŒ¨"
