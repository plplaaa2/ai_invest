import streamlit as st
import pandas as pd
from common import *
from fpdf import FPDF

# app.py ë‚´ì˜ is_filtered í•¨ìˆ˜ë¥¼ ì´ ë‚´ìš©ìœ¼ë¡œ êµì²´í•˜ì„¸ìš”.
def is_filtered(title, summary, g_inc, g_exc, l_inc="", l_exc=""):
    """ì œëª©(Title)ë§Œì„ ê¸°ì¤€ìœ¼ë¡œ ì „ì—­/ê°œë³„ í•„í„°ë¥¼ ì ìš©í•©ë‹ˆë‹¤."""
    # ğŸ¯ 1. ëŒ€ì†Œë¬¸ì ë¬´ì‹œ ë° ê³µë°± ì •ë¦¬ 
    text = title.lower().strip()
    
    # ğŸ¯ 2. ì œì™¸ í•„í„° (Exclude): ì œëª©ì— ë‹¨ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ì¦‰ì‹œ íƒˆë½ 
    exclude_str = f"{g_exc},{l_exc}"
    exc_tags = [t.strip().lower() for t in exclude_str.split(",") if t.strip()]
    if any(t in text for t in exc_tags): 
        return False
    
    # ğŸ¯ 3. ì „ì—­ í¬í•¨ì–´ (Global Include): ì„¤ì •ëœ ê²½ìš°, ì œëª©ì— ë°˜ë“œì‹œ ìˆì–´ì•¼ í†µê³¼ 
    g_inc_tags = [t.strip().lower() for t in g_inc.split(",") if t.strip()]
    if g_inc_tags and not any(t in text for t in g_inc_tags):
        return False
        
    # ğŸ¯ 4. ê°œë³„(í”¼ë“œ) í¬í•¨ì–´ (Local Include): ì„¤ì •ëœ ê²½ìš°, ì œëª©ì— ë°˜ë“œì‹œ ìˆì–´ì•¼ í†µê³¼ 
    l_inc_tags = [t.strip().lower() for t in l_inc.split(",") if t.strip()]
    if l_inc_tags and not any(t in text for t in l_inc_tags):
        return False
    
    return True # ëª¨ë“  ê²€ì‚¬ë¥¼ í†µê³¼í•¨

def get_ai_summary(title, content, system_instruction=None, role="filter"):
    """ë‰´ìŠ¤ íŒë… ë˜ëŠ” ìš”ì•½ì„ ìœ„í•´ AI ëª¨ë¸ì„ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    now_time = get_now_kst().strftime('%Y-%m-%d %H:%M:%S')
    
    # ğŸ¯ 1. ì„¤ì • ë° ëª¨ë¸ ì •ë³´ ë¡œë“œ
    cfg = data.get("filter_model") if role == "filter" else data.get("analyst_model")
    base_url = cfg.get("url", "").rstrip('/')
    model_name = cfg.get("name")
    
    # ì§€ì¹¨ ì„¤ì •
    user_prompt = system_instruction if system_instruction else cfg.get("prompt", "")
    final_role = f"í˜„ì¬ ì‹œê°: {now_time}\në¶„ì„ ì§€ì¹¨: {user_prompt}"

    # ğŸ¯ 2. [ìˆ˜ì • í¬ì¸íŠ¸] í´ë¼ìš°ë“œ(Google ì§ì ‘ í˜¸ì¶œ) ì—¬ë¶€ íŒë³„
    # ëª¨ë¸ëª…ì— geminiê°€ ìˆë”ë¼ë„, URLì´ êµ¬ê¸€ ì£¼ì†Œì¼ ë•Œë§Œ 'ì§„ì§œ í´ë¼ìš°ë“œ'ë¡œ íŒì •í•©ë‹ˆë‹¤.
    is_direct_google = "generativelanguage.googleapis.com" in base_url
    
    # API í‚¤ ì„ íƒ ë¡œì§ ê°•í™”
    if is_direct_google:
        # êµ¬ê¸€ ê³µì‹ ì„œë¹„ìŠ¤ëŠ” ë¬´ì¡°ê±´ gemini_api_key ì‚¬ìš©
        api_key = config.get("gemini_api_key", "")
    else:
        # ê·¸ ì™¸(ë¡œì»¬/OpenAI ë“±)ëŠ” ì„¤ì •ëœ ê°œë³„ í‚¤ -> OpenAI í‚¤ ìˆœìœ¼ë¡œ ì‹œë„
        api_key = cfg.get("key") if cfg.get("key") else config.get("openai_api_key", "")

    # ğŸ¯ 3. í˜¸ì¶œ ë°©ì‹ ë¶„ê¸° (URL êµ¬ì¡° ê¸°ë°˜)
    if is_direct_google:
        # ğŸŒ [Case A] êµ¬ê¸€ ì„œë²„ ì§ì ‘ í˜¸ì¶œ ë°©ì‹ (Gemini API ê·œê²©)
        url = f"{base_url}/v1beta/models/{model_name}:generateContent?key={api_key}"
        headers = {"Content-Type": "application/json"}
        payload = {
            "contents": [{
                "parts": [{"text": f"ì‹œìŠ¤í…œ ì§€ì¹¨: {final_role}\n\nì‚¬ìš©ì ì…ë ¥:\nì œëª©: {title}\në³¸ë¬¸: {content}"}]
            }],
            "generationConfig": {"temperature": cfg.get("temperature", 0.3)}
        }
    else:
        # ğŸ  [Case B] ë¡œì»¬ ì„œë²„(Ollama/Open WebUI) ë˜ëŠ” OpenAI ë°©ì‹ (Chat Completion ê·œê²©)
        # ì´ì œ gemini-3-flash-preview:cloud ëª¨ë¸ë„ ì£¼ì†Œê°€ ë¡œì»¬ì´ë©´ ì´ ë¡œì§ì„ íƒ‘ë‹ˆë‹¤.
        url = f"{base_url}/chat/completions"
        headers = {"Content-Type": "application/json"}
        if api_key:
            headers["Authorization"] = f"Bearer {api_key}"
            
        payload = {
            "model": model_name,
            "messages": [
                {"role": "system", "content": final_role},
                {"role": "user", "content": f"ì œëª©: {title}\në³¸ë¬¸: {content}"}
            ],
            "temperature": cfg.get("temperature", 0.3)
        }

    try:
        # ğŸ¯ 4. ìš”ì²­ ì „ì†¡ (íƒ€ì„ì•„ì›ƒ 10ë¶„)
        resp = requests.post(url, json=payload, headers=headers, timeout=600)
        resp.raise_for_status()
        result = resp.json()

        # ğŸ¯ 5. ì‘ë‹µ êµ¬ì¡° íŒë³„ ë° ì¶”ì¶œ
        # êµ¬ê¸€ ì§ì ‘ í˜¸ì¶œì¸ ê²½ìš° 'candidates' êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤.
        if "candidates" in result:
            return result['candidates'][0]['content']['parts'][0]['text']
        # ë¡œì»¬ ì„œë²„/OpenAIì¸ ê²½ìš° 'choices' êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤.
        else:
            return result['choices'][0]['message']['content']

    except requests.exceptions.Timeout:
        return "âŒ [TIMEOUT] AI ë¶„ì„ ì‹œê°„ì´ 10ë¶„ì„ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤."
    except Exception as e:
        print(f"[{now_time}] AI ë¶„ì„ ì—ëŸ¬: {str(e)}")
        return f"âŒ [ERROR] AI ë¶„ì„ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}"
        
@st.dialog("ğŸ“Š AI ì •ë°€ ë¶„ì„ ë¦¬í¬íŠ¸")
def show_analysis_dialog(title, summary_text, pub_dt, role="filter"): 
    with st.spinner("AIê°€ ë‰´ìŠ¤ë¥¼ ì‹¬ì¸µ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        enhanced_title = f"(ê¸°ì‚¬ì‘ì„±ì¼: {pub_dt}) {title}"
        # ì—¬ê¸°ì„œ ë°©ê¸ˆ ìˆ˜ì •í•œ get_ai_summaryê°€ í˜¸ì¶œë˜ë©´ì„œ 
        # Add-on ì„¤ì •ì˜ í‚¤ë¥¼ ì°¾ì•„ Geminië¥¼ íƒœìš¸ ê²ƒì…ë‹ˆë‹¤.
        analysis = get_ai_summary(enhanced_title, summary_text, role=role)
    
    st.markdown(f"### {title}")
    st.caption(f"ğŸ“… ê¸°ì‚¬ ì‘ì„±ì¼: {pub_dt}") 
    st.divider()
    
    st.markdown(analysis)
    st.divider()
    
    with st.expander("ê¸°ì‚¬ ì›ë¬¸ ìš”ì•½ ë³´ê¸°"):
        st.write(summary_text)

    # ğŸ¯ [ë³´ì™„ í¬ì¸íŠ¸] ëª¨ë¸ ì •ë³´ í‘œì‹œ ë¡œì§ ìµœì í™”
    cfg = data.get("filter_model" if role == "filter" else "analyst_model", {})
    display_model = cfg.get("name", "Unknown Model")
    
    # ğŸ’¡ UI ì„¤ì •(cfg)ì´ë‚˜ Add-on ì„¤ì •(config) ì¤‘ í•˜ë‚˜ë¼ë„ í‚¤ê°€ ìˆìœ¼ë©´ í´ë¼ìš°ë“œë¡œ í‘œì‹œ
    has_openai = cfg.get("key") or config.get("openai_api_key")
    has_gemini = cfg.get("key") or config.get("gemini_api_key")

    if has_gemini and "gemini" in display_model.lower():
        display_model = f"âœ¨ Gemini ({display_model})"
    elif has_openai and "gpt" in display_model.lower():
        display_model = f"ğŸŒ OpenAI ({display_model})"
    else:
        # í‚¤ê°€ ì—†ê±°ë‚˜ ëª¨ë¸ëª…ì´ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ë¡œì»¬ë¡œ í‘œì‹œ
        display_model = f"ğŸ  Local ({display_model})"

    analysis_time = get_now_kst().strftime('%H:%M:%S')
    
    st.caption(
        f"ğŸ¤– ì‚¬ìš© ëª¨ë¸: {display_model} | "
        f"ğŸ•’ ë¶„ì„ ì‹œê°: {analysis_time} | "
        f"ğŸ“Š ë¶„ì„ ëª¨ë“œ: {'ë‹¨ê¸° íŒë…' if role == 'filter' else 'ì‹¬ì¸µ ì „ëµ'}"
    )

def check_filters(title, include_str, exclude_str):
    title = title.lower().strip()
    if exclude_str:
        exc_tags = [t.strip().lower() for t in exclude_str.split(",") if t.strip()]
        if any(t in title for t in exc_tags): return False
    if include_str:
        inc_tags = [t.strip().lower() for t in include_str.split(",") if t.strip()]
        if not any(t in title for t in inc_tags): return False
    return True

def clean_html(raw_html):
    if not raw_html: return "ìš”ì•½ ë‚´ìš© ì—†ìŒ"
    soup = BeautifulSoup(raw_html, "html.parser")
    for s in soup(['style', 'script', 'span']): s.decompose()
    return re.sub(r'\s+', ' ', soup.get_text()).strip()
    
def parse_rss_date(date_str):
    try:
        p = feedparser._parse_date(date_str)
        return datetime.fromtimestamp(time.mktime(p))
    except: return datetime.now()

def load_pending_files(range_type, target_feed=None):
    """
    ë‹¨ê³„ë³„ ë¡œê·¸ë¥¼ í†µí•´ ì›ì¸ì„ íŒŒì•…í•˜ëŠ” ë‰´ìŠ¤ ë¡œë”
    """
    news_list = []
    if not os.path.exists(PENDING_PATH):
        st.error(f"âŒ ê²½ë¡œ ë¯¸ì¡´ì¬: {PENDING_PATH}")
        return news_list
        
    # ğŸ” ë¡œê·¸ 1: ë¬¼ë¦¬ì  íŒŒì¼ ê²€ìƒ‰
    all_files = os.listdir(PENDING_PATH)
    target_files = [f for f in all_files if f.endswith(".json") or f.endswith(".txt")]
    print(f"ğŸ” [STEP 1] ì „ì²´ íŒŒì¼: {len(all_files)}ê°œ | ëŒ€ìƒ í™•ì¥ì: {len(target_files)}ê°œ")

    now_kst = get_now_kst()
    today_date = now_kst.date()
    # ì‹œê°„ëŒ€ ì •ë³´ ì œê±°(naive) ë²„ì „ ì¤€ë¹„ (ë¹„êµìš©)
    one_week_ago = (now_kst - timedelta(days=7)).replace(tzinfo=None)
    
    parse_fail = 0
    filter_fail = 0

    for filename in target_files:
        fpath = os.path.join(PENDING_PATH, filename)
        try:
            with open(fpath, 'r', encoding='utf-8') as f:
                if filename.endswith(".json"):
                    data = json.load(f)
                    title = data.get('title', 'ì œëª© ì—†ìŒ')
                    pub_str = data.get('pub_dt', '')
                    
                    # ğŸ¯ ë‚ ì§œ íŒŒì‹± ê°•í™” (pub_dt_str í˜•ì‹: %Y-%m-%d %H:%M:%S)
                    try:
                        pub_dt = datetime.strptime(pub_str, '%Y-%m-%d %H:%M:%S')
                    except:
                        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ íŒŒì¼ ìˆ˜ì • ì‹œê°„ìœ¼ë¡œ ê°•ì œ ë³µêµ¬
                        pub_dt = datetime.fromtimestamp(os.path.getmtime(fpath))
                    
                    link = data.get('link', '')
                    summary = data.get('summary', '')
                    source = data.get('source', 'ì €ì¥ëœ ë°ì´í„°')
                else:
                    lines = f.read().splitlines()
                    if len(lines) < 3: continue
                    title = lines[0].replace("ì œëª©: ", "")
                    pub_str = lines[2].replace("ë‚ ì§œ: ", "")
                    pub_dt = parse_rss_date(pub_str)
                    link = lines[1].replace("ë§í¬: ", "")
                    summary = "\n".join(lines[3:]).replace("ìš”ì•½: ", "")
                    source = "ì €ì¥ëœ ë°ì´í„°"

                # ğŸ” ë¡œê·¸ 2: í•„í„°ë§ ì „ ë°ì´í„° í™•ë³´ í™•ì¸
                # ì‹œê°„ëŒ€ ì •ë³´ê°€ ì„ì—¬ ë¹„êµ ì—ëŸ¬ê°€ ë‚˜ëŠ” ê²ƒì„ ë°©ì§€
                pub_dt_naive = pub_dt.replace(tzinfo=None) if pub_dt.tzinfo else pub_dt
                
                # í•„í„°ë§ ë¡œì§
                if range_type == "ì˜¤ëŠ˜" and pub_dt_naive.date() != today_date:
                    filter_fail += 1
                    continue
                if range_type == "ì¼ì£¼ì¼" and pub_dt_naive < one_week_ago:
                    filter_fail += 1
                    continue
                
                if target_feed:
                    if not check_filters(title, target_feed.get('include', ""), target_feed.get('exclude', "")):
                        filter_fail += 1
                        continue
                
                news_list.append({
                    "title": title, "link": link, "published": pub_str, 
                    "summary": summary, "pub_dt": pub_dt_naive, "source": source
                })

        except Exception as e:
            parse_fail += 1
            print(f"âŒ [ì—ëŸ¬] {filename} ë¡œë“œ ì‹¤íŒ¨: {e}")
            continue
            
    # ğŸ” ë¡œê·¸ 3: ìµœì¢… ê²°ê³¼ ì§‘ê³„
    print(f"âœ… [STEP 2] ìµœì¢… ë¡œë“œ: {len(news_list)}ê°œ | íŒŒì‹±ì‹¤íŒ¨: {parse_fail} | ê¸°ê°„/í•„í„°ì œì™¸: {filter_fail}")
    
    news_list.sort(key=lambda x: x['pub_dt'], reverse=True)
    return news_list

def save_data(data):
    """ë³€ê²½ëœ ì„¤ì • ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì•ˆì „í•˜ê²Œ ì €ì¥í•©ë‹ˆë‹¤."""
    # í´ë”ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    os.makedirs(os.path.dirname(CONFIG_PATH), exist_ok=True)
    
    # íŒŒì¼ì„ ì—´ì–´ ë”•ì…”ë„ˆë¦¬ ë°ì´í„°ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.
    with open(CONFIG_PATH, 'w', encoding='utf-8') as f:
        # í•œê¸€ ê¹¨ì§ ë°©ì§€ ë° ê°€ë…ì„±ì„ ìœ„í•´ ì˜µì…˜ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
        json.dump(data, f, ensure_ascii=False, indent=2)


# --- 3. UI ë° CSS ì„¤ì • ---
st.set_page_config(page_title="AI Analyst", layout="wide")

st.markdown("""
    <style>
    [data-testid="stPopoverBody"] { width: 170px !important; padding: 10px !important; }
    [data-testid="stPopoverBody"] button { padding: 2px 5px !important; margin-bottom: 2px !important; height: auto !important; font-size: 14px !important; }
    [data-testid="stSidebar"] { display: none; }
    [data-testid="stMetricValue"] { font-size: 28px !important; }
    </style>
    """, unsafe_allow_html=True)


if 'active_menu' not in st.session_state: st.session_state.active_menu = "ë‰´ìŠ¤"
if 'current_feed_idx' not in st.session_state: st.session_state.current_feed_idx = "all"
if 'page_number' not in st.session_state: st.session_state.page_number = 1

# --- 4. ìµœìƒë‹¨ ëŒ€ë©”ë‰´ ---
st.title("ğŸ¤– AI Analyst System")
m_cols = st.columns(3)
menu_items = [("ğŸ“¡ ë‰´ìŠ¤ ìŠ¤íŠ¸ë¦¬ë°", "ë‰´ìŠ¤"), ("ğŸ›ï¸ AI íˆ¬ì ë³´ê³ ì„œ", "AI"), ("âš™ï¸ ì„¤ì •", "ì„¤ì •")]

for i, (label, m_key) in enumerate(menu_items):
    if m_cols[i].button(label, width='stretch', type="primary" if st.session_state.active_menu == m_key else "secondary"):
        st.session_state.active_menu = m_key; st.rerun()

st.divider()

# --- 5. ë©”ë‰´ë³„ ë³¸ë¬¸ í™”ë©´ êµ¬ì„± ---

if st.session_state.active_menu == "ì„¤ì •":
    st.subheader("âš™ï¸ ë¡œì»¬ ë©€í‹° AI ì„œë²„ ë° ì‹œìŠ¤í…œ ì„¤ì •")
    
    # ì„¸ ê°€ì§€ ì„¤ì • íƒ­ìœ¼ë¡œ í†µí•© ê´€ë¦¬
    tab_f, tab_a, tab_g = st.tabs(["ğŸ¯ ë‰´ìŠ¤ íŒë… (Filter)", "ğŸ›ï¸ íˆ¬ì ë¶„ì„ (Analyst)", "ğŸŒ ì¼ë°˜ ì„¤ì •"])

    with tab_f:
        st.markdown("#### ğŸ“¡ ë‰´ìŠ¤ ìŠ¤íŠ¸ë¦¬ë° ìš”ì•½ìš© ëª¨ë¸")
        f_cfg = data.get("filter_model")
        # ê³ ìœ  í‚¤: f_url_input
        f_url = st.text_input("API ì„œë²„ ì£¼ì†Œ (URL)", value=f_cfg.get("url"), help="ì˜ˆ: http://192.168.1.2:1234/v1", key="f_url_input")
        f_name = st.text_input("ëª¨ë¸ëª…", value=f_cfg.get("name"), key="f_name_input")
        f_prompt = st.text_area("ê¸°ë³¸ ìš”ì•½ ì§€ì¹¨", value=f_cfg.get("prompt"), height=100, key="f_prompt_input")
        
        if st.button("ğŸ’¾ íŒë… ëª¨ë¸ ì„¤ì • ì €ì¥", width='stretch'):
            data["filter_model"].update({"url": f_url, "name": f_name, "prompt": f_prompt})
            save_data(data); st.success("âœ… íŒë… ëª¨ë¸ ì„¤ì • ì €ì¥ ì™„ë£Œ!")

    with tab_a:
        st.markdown("#### ğŸ›ï¸ íˆ¬ì ë³´ê³ ì„œ ìƒì„±ìš© ëª¨ë¸")
        a_cfg = data.get("analyst_model")
        # ê³ ìœ  í‚¤: a_url_input
        a_url = st.text_input("API ì„œë²„ ì£¼ì†Œ (URL)", value=a_cfg.get("url"), help="ì˜ˆ: http://192.168.1.105:11434/v1", key="a_url_input")
        a_name = st.text_input("ëª¨ë¸ëª…", value=a_cfg.get("name"), key="a_name_input")
        
        if st.button("ğŸ’¾ ë¶„ì„ ëª¨ë¸ ì„¤ì • ì €ì¥", width='stretch'):
            data["analyst_model"].update({"url": a_url, "name": a_name})
            save_data(data); st.success("âœ… ë¶„ì„ ëª¨ë¸ ì„¤ì • ì €ì¥ ì™„ë£Œ!")

    with tab_g:
        st.markdown("#### âš™ï¸ ì‹œìŠ¤í…œ ê³µí†µ ë° ë‰´ìŠ¤ ìˆ˜ì§‘ ì„¤ì •")
        col1, col2 = st.columns(2)
        
        # 1. ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë³´ê´€ ì„¤ì •
        new_retention = col1.slider("ë‰´ìŠ¤ íŒŒì¼ ë³´ê´€ ê¸°ê°„ (ì¼)", 1, 30, value=data.get("retention_days", 7), key="cfg_retention_days")
        new_interval = col2.number_input("RSS ìˆ˜ì§‘ ì£¼ê¸° (ë¶„)", 1, value=data.get("update_interval", 10), key="cfg_update_interval")
        
        st.divider()
        
        st.markdown("#### ğŸ“‘ AI íˆ¬ì ë³´ê³ ì„œ ìë™í™”")
        # 2. ìë™ ìƒì„± ë° ì‹œê°„ ì„¤ì • (stock_collector.pyì—ì„œ ì´ ê°’ì„ ì½ì–´ ì •ì‹œ ê°€ë™)
        col_auto, col_time = st.columns([0.4, 0.6])
        auto_gen = col_auto.toggle("ë§¤ì¼ ë³´ê³ ì„œ ìë™ ìƒì„±", value=data.get("report_auto_gen", False), key="cfg_report_auto_gen")
        gen_time = col_time.text_input("ìƒì„± ì‹œê°„ (24ì‹œê°„ì œ, ì˜ˆ: 08:00)", value=data.get("report_gen_time", "08:00"), key="cfg_report_gen_time")
        
        # 3. ë¶„ì„ ë‰´ìŠ¤ ê°œìˆ˜ ì„¤ì • (ìµœëŒ€ 500ê°œ í™•ì¥ ë°˜ì˜)
        report_news_count = st.slider("ë¶„ì„ í¬í•¨ ë‰´ìŠ¤ ê°œìˆ˜ (ìµœëŒ€ 500ê°œ)", 10, 500, value=data.get("report_news_count", 100), key="cfg_report_news_count")

        if st.button("ğŸ’¾ ëª¨ë“  ì‹œìŠ¤í…œ ì„¤ì • ì €ì¥", width='stretch', type="primary"):
            # ğŸ¯ [ë°ì´í„° êµ¬ì¡° ë™ê¸°í™”]
            data.update({
                "retention_days": new_retention,
                "update_interval": new_interval,
                "report_auto_gen": auto_gen,
                "report_gen_time": gen_time,
                "report_news_count": report_news_count
            })
            
            # ğŸ’¡ ìˆ˜ì§‘ê¸° í˜¼ì„ ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ êµ¬í˜• ì„¤ì • ì œê±°
            if "report_days" in data:
                del data["report_days"]
                
            save_data(data)
            st.success("âœ… ì‹œìŠ¤í…œ ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ë‰´ìŠ¤ ì²˜ë¦¬ëŸ‰ì´ 500ê°œë¡œ í™•ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()

    st.write("") # ê°„ê²© ì¡°ì ˆ
        

# [2. ë‰´ìŠ¤ ìŠ¤íŠ¸ë¦¬ë°]
if st.session_state.active_menu == "ë‰´ìŠ¤":    
    # ğŸ¯ 1. ì‚¬ì´ë“œë°” ìƒíƒœ ê´€ë¦¬ ì„¸ì…˜ ì´ˆê¸°í™”
    if 'show_rss_sidebar' not in st.session_state:
        st.session_state.show_rss_sidebar = False # ê¸°ë³¸ìœ¼ë¡œ ë‹«ì•„ë‘ì–´ ê´‘í­ í™”ë©´ í™•ë³´

    # ğŸ¯ 2. ìµœìƒë‹¨ ì»¨íŠ¸ë¡¤ ë°”
    t_col1, t_col2 = st.columns([0.8, 0.2])

    try:
        if st.session_state.current_feed_idx == "all":
            current_f_name = "ğŸ  ì „ì²´ ë‰´ìŠ¤"
        else:
            # ì¸ë±ìŠ¤ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ ë²”ìœ„ ì²´í¬
            idx = int(st.session_state.current_feed_idx)
            feeds = data.get('feeds', [])
            if 0 <= idx < len(feeds):
                current_f_name = feeds[idx]['name']
            else:
                # ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´ ì•ˆì „í•˜ê²Œ 'ì „ì²´'ë¡œ ë³µêµ¬
                st.session_state.current_feed_idx = "all"
                current_f_name = "ğŸ  ì „ì²´ ë‰´ìŠ¤"
    except (ValueError, IndexError, TypeError):
        # ìˆ«ìê°€ ì•„ë‹ˆê±°ë‚˜ ê°’ì´ ì—†ì„ ê²½ìš° 'ì „ì²´'ë¡œ ë³µêµ¬
        st.session_state.current_feed_idx = "all"
        current_f_name = "ğŸ  ì „ì²´ ë‰´ìŠ¤"
    # ---------------------------------------
    t_col1.subheader(f"ğŸ“¡ {current_f_name}")
    
    # ë²„íŠ¼ì„ ìš°ì¸¡ ëì— ë°°ì¹˜í•˜ì—¬ ì‚¬ì´ë“œë°” ì—´ê¸° ìœ ë„
    btn_text = "ğŸ“‚ RSS ë‹«ê¸°" if st.session_state.show_rss_sidebar else "ğŸ“‚ RSS ê´€ë¦¬"
    if t_col2.button(btn_text, width='stretch', type="secondary"):
        st.session_state.show_rss_sidebar = not st.session_state.show_rss_sidebar
        st.rerun()

# ğŸ¯ 3. ë™ì  ì»¬ëŸ¼ ë°°ì¹˜ (ìš°ì¸¡ ì‚¬ì´ë“œë°” ì²´ì œ)
    # ë³¸ë¬¸(Main)ì„ ë¨¼ì € ë°°ì¹˜í•˜ê³ , ì‚¬ì´ë“œë°”(Side)ë¥¼ ë’¤ì— ë°°ì¹˜í•©ë‹ˆë‹¤.
    if st.session_state.show_rss_sidebar:
        col_main, col_side = st.columns([0.75, 0.25]) 
    else:
        col_main, col_side = st.columns([0.999, 0.001])

    with col_main:
        full_list = []
        target = data.get('feeds', []) if st.session_state.current_feed_idx == "all" else [data['feeds'][st.session_state.current_feed_idx]]
        
        for f_info in target:
            try:
                parsed = feedparser.parse(f_info['url'])
                for e in parsed.entries:
                    # ê°•í™”ëœ ì œëª© í•„í„° ì ìš© (ë²„ê·¸ ìˆ˜ì •ë¨)
                    if is_filtered(e.title, e.get('summary', ''), 
                                   data.get("global_include", ""), data.get("global_exclude", ""),
                                   f_info.get('include', ""), f_info.get('exclude', "")):
                        e['source'] = f_info['name']
                        full_list.append(e)
            except: continue
            
        full_list.sort(key=lambda x: x.get('published_parsed', 0), reverse=True)
        
        if full_list:
            items_per_page = 10
            total_pages = math.ceil(len(full_list) / items_per_page)
            start_idx = (st.session_state.page_number - 1) * items_per_page
            
            for entry in full_list[start_idx : start_idx + items_per_page]:
                with st.container(border=True):
                    st.caption(f"ğŸ“ {entry.get('source')} | {entry.get('published', '')}")
                    st.markdown(f"#### {entry.get('title')}")
                    
                    cleaned_summary = clean_html(entry.get('summary', ''))
                    st.write(cleaned_summary[:200] + "...")
                    
                    btn_c1, btn_c2 = st.columns([0.2, 0.8])
                    btn_c1.link_button("ğŸŒ ì›ë¬¸", entry.get('link', '#'), width='stretch')
                    if btn_c2.button("ğŸ¤– AI ìš”ì•½", key=f"ai_{entry.get('link')}", width='stretch'):
                        show_analysis_dialog(entry.get('title'), cleaned_summary, entry.get('published', 'ë‚ ì§œ ë¯¸ìƒ'), role="filter")

            # í˜ì´ì§€ë„¤ì´ì…˜ ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼í•˜ë˜ ë„ì–´ì“°ê¸° ì •ëˆ)
            st.write("")
            
            # --- [ 4. ê°œì„ ëœ í˜ì´ì§€ ë‚´ë¹„ê²Œì´í„° ] ---
            if total_pages > 1:
                # 10ë‹¨ìœ„ ë­‰ì¹˜ ê³„ì‚°
                current_group = (st.session_state.page_number - 1) // 10
                start_page = current_group * 10 + 1
                end_page = min(start_page + 9, total_pages)
                
                # ë²„íŠ¼ ë ˆì´ì•„ì›ƒ (ì´ì „ + ìˆ«ì 10ê°œ + ë‹¤ìŒ)
                nav_cols = st.columns([0.6] + [1] * (end_page - start_page + 1) + [0.6])
                
                # [ < ] ì´ì „ 10ê°œ ë­‰ì¹˜ ì´ë™
                if start_page > 1:
                    if nav_cols[0].button("<", key="prev_group"):
                        st.session_state.page_number = start_page - 1
                        st.rerun()
                
                # ìˆ«ì ë²„íŠ¼ë“¤
                for i, page_idx in enumerate(range(start_page, end_page + 1)):
                    if nav_cols[i+1].button(
                        str(page_idx), 
                        key=f"page_{page_idx}",
                        type="primary" if st.session_state.page_number == page_idx else "secondary",
                        width='stretch'
                    ):
                        st.session_state.page_number = page_idx
                        st.rerun()
                
                # [ > ] ë‹¤ìŒ 10ê°œ ë­‰ì¹˜ ì´ë™
                if end_page < total_pages:
                    if nav_cols[-1].button(">", key="next_group"):
                        st.session_state.page_number = end_page + 1
                        st.rerun()
        else:
            st.warning("ğŸ“¡ í‘œì‹œí•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
# --- ì‚¬ì´ë“œë°” (RSS ê´€ë¦¬) êµ¬ì—­ (ì˜¤ë¥¸ìª½) ---
    with col_side:
        if st.session_state.show_rss_sidebar:
            st.markdown("### ğŸ“Œ RSS ê´€ë¦¬")
            
            # ì „ì²´ ë³´ê¸° ë²„íŠ¼
            is_all = st.session_state.current_feed_idx == "all"
            if st.button("ğŸ  ì „ì²´ ë³´ê¸°", width='stretch', type="primary" if is_all else "secondary"):
                st.session_state.current_feed_idx = "all"
                st.session_state.page_number = 1
                st.rerun()
            
            st.write("")
            
# í”¼ë“œ ë¦¬ìŠ¤íŠ¸ ë°˜ë³µë¬¸ (ê¸°ì¡´ ë¡œì§ ìœ ì§€í•˜ë©° ë„ì–´ì“°ê¸° ì •ëˆ)
            for i, f in enumerate(data.get('feeds', [])):
                is_active = st.session_state.current_feed_idx == i
# 8:2 ë¹„ìœ¨ë¡œ ê°€ë¡œ ì»¬ëŸ¼ ìƒì„±
                btn_col, opt_col = st.columns([0.82, 0.18], gap="small")
                


            # 1. ë©”ì¸ í”¼ë“œ ì„ íƒ ë²„íŠ¼
                with btn_col:
                    if st.button(
                        f"ğŸ“¡ {f['name']}", 
                        key=f"f_{i}", 
                        width='stretch', 
                        type="primary" if is_active else "secondary"
                    ):
                        st.session_state.current_feed_idx = i
                        st.session_state.page_number = 1
                        st.rerun()
                        
                    # A. í¸ì§‘ ë²„íŠ¼
                with opt_col:
                    with st.popover("", width='stretch'):
                        col_ed, col_fi, col_de = st.columns(3)
                        if col_ed.button("í¸ì§‘", key=f"ed_{i}", width='stretch'):
                            @st.dialog("í”¼ë“œ ìˆ˜ì •", width="small")
                            def ed_diag(idx=i):
                                fe = data['feeds'][idx]
                                n = st.text_input("ì´ë¦„", value=fe['name'])
                                u = st.text_input("URL", value=fe['url'])
                                if st.button("ì €ì¥"):
                                    data['feeds'][idx].update({"name": n, "url": u})
                                    save_data(data)
                                    st.rerun()
                            ed_diag()
                    
                        # B. í•„í„° ë²„íŠ¼
                        if col_fi.button("í•„í„°", key=f"fi_{i}", width='stretch'):
                            @st.dialog("í‚¤ì›Œë“œ í•„í„°", width="small")
                            def fi_diag(idx=i):
                                fe = data['feeds'][idx]
                                inc = st.text_area("í¬í•¨ í‚¤ì›Œë“œ", value=fe.get('include', ""))
                                exc = st.text_area("ì œì™¸ í‚¤ì›Œë“œ", value=fe.get('exclude', ""))
                                if st.button("í•„í„° ì ìš©"):
                                    data['feeds'][idx].update({"include": inc, "exclude": exc})
                                    save_data(data)
                                    st.rerun()
                            fi_diag()
                        
                        # C. ì‚­ì œ ë²„íŠ¼
                        if col_de.button("ì‚­ì œ", key=f"de_{i}", width='stretch'):
                            data['feeds'].pop(i)
                            save_data(data)
                            st.rerun()
                
                    # í”¼ë“œ ì•„ì´í…œ ê°„ì˜ ì‹œê°ì  ê°„ê²© ì¶”ê°€
                    st.write("")
            
            st.divider()
            
            # í”¼ë“œ ì¶”ê°€ ë²„íŠ¼
            if st.button("â• ìƒˆ RSS ì¶”ê°€", width='stretch'):
                @st.dialog("ìƒˆ RSS ë“±ë¡")
                def add_diag():
                    n = st.text_input("í”¼ë“œ ì´ë¦„ (ì˜ˆ: ì—°í•©ë‰´ìŠ¤)")
                    u = st.text_input("RSS URL ì£¼ì†Œ")
                    if st.button("ë“±ë¡ ì™„ë£Œ"):
                        data['feeds'].append({"name": n, "url": u, "include": "", "exclude": ""})
                        save_data(data); st.rerun()
                add_diag()

            # ì „ì—­ í•„í„° ì„¤ì • êµ¬ì—­ (ì‚¬ì´ë“œë°” ì•ˆì— í¬í•¨)
            with st.expander("ğŸŒ ì „ì—­ í•„í„° ì„¤ì •", expanded=False):
                g_inc = st.text_area("ì „ì—­ í¬í•¨ í‚¤ì›Œë“œ", value=data.get("global_include", ""), help="ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„")
                g_exc = st.text_area("ì „ì—­ ì œì™¸ í‚¤ì›Œë“œ", value=data.get("global_exclude", ""), help="ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„")
                if st.button("ì „ì—­ í•„í„° ì €ì¥", width='stretch'):
                    data.update({"global_include": g_inc, "global_exclude": g_exc})
                    save_data(data); st.toast("ì „ì—­ í•„í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            # ğŸ¯ ì‚¬ì´ë“œë°”ê°€ ìˆ¨ê²¨ì¡Œì„ ë•ŒëŠ” ì•„ì£¼ ì–‡ì€ ê³µê°„ë§Œ ìœ ì§€í•˜ê±°ë‚˜ ë¹„ì›Œë‘¡ë‹ˆë‹¤.
            st.empty()

# [3. AI íˆ¬ì ë³´ê³ ì„œ]
elif st.session_state.active_menu == "AI":
    st.subheader("ğŸ“‘ AI íˆ¬ì ì‚¬ë ¹ë¶€ ë³´ê³ ì„œ")
    
    # 1. ê¸°ì´ˆ ì„¤ì • (ê¸°ì¡´ ê²½ë¡œ ë° ì„¸ì…˜ ìœ ì§€)    
    DIR_MAP = {'daily': '01_daily', 'weekly': '02_weekly', 'monthly': '03_monthly'}
    
    if "report_chat_history" not in st.session_state:
        st.session_state.report_chat_history = []
    if "last_report_content" not in st.session_state:
        st.session_state.last_report_content = ""

    # ğŸ¯ íƒ­ êµ¬ì„±: ì¼ê°„, ì£¼ê°„, ì›”ê°„
    tabs = st.tabs(["ğŸ“… ì¼ê°„ ë³´ê³ ì„œ", "ğŸ—“ï¸ ì£¼ê°„ ë³´ê³ ì„œ", "ğŸ“Š ì›”ê°„ ë³´ê³ ì„œ"])
    r_types = ["daily", "weekly", "monthly"]
    r_days_map = {"daily": data.get("report_days", 1), "weekly": 7, "monthly": 30}

    # íƒ­ë³„ ë£¨í”„ ì‹œì‘
    for i, tab in enumerate(tabs):
        r_type = r_types[i]
        r_days = r_days_map[r_type]
        
        # ì‚¬ë ¹ê´€ë‹˜ í´ë” ë§¤ì¹­
        target_dir = os.path.join(REPORT_DIR, DIR_MAP.get(r_type, "05_etc"))
        os.makedirs(target_dir, exist_ok=True)

        with tab:
            st.markdown(f"#### ğŸ›ï¸ {r_type.upper()} ë¶„ì„ ì»¨íŠ¸ë¡¤")
            
            # ğŸ“ ê³¼ê±° ê¸°ë¡ ìŠ¤ìº” (latest.txt ì œì™¸)
            r_files = sorted([f for f in os.listdir(target_dir) if f.endswith(".txt") and f != "latest.txt"], reverse=True)
            
            c1, c2 = st.columns([0.8, 0.2])
            selected_f = c1.selectbox(f"ê¸°ë¡ì‹¤ ({r_type})", r_files, key=f"sel_{r_type}", label_visibility="collapsed")
            
            if c2.button("ğŸ“– ë¡œë“œ", key=f"load_{r_type}", width='stretch', disabled=not r_files):
                with open(os.path.join(target_dir, selected_f), "r", encoding="utf-8") as f:
                    st.session_state.last_report_content = f.read()
                st.rerun()

            st.divider()

            # ğŸš€ ë³´ê³ ì„œ ìƒì„± ë²„íŠ¼
            if st.button(f"ğŸš€ ìƒˆ {r_type.upper()} ë³´ê³ ì„œ ìƒì„± ({r_days}ì¼ ë¶„ì„)", type="primary", width='stretch', key=f"gen_{r_type}"):
                st.info(f"ğŸ” ì‹œìŠ¤í…œ ê²½ë¡œ í™•ì¸ ì¤‘...")
                abs_path = os.path.abspath(PENDING_PATH)
                st.write(f"ğŸ“ í˜„ì¬ PENDING_PATH (ì ˆëŒ€ê²½ë¡œ): `{abs_path}`")
                
                if os.path.exists(abs_path):
                    all_files = os.listdir(abs_path)
                    st.write(f"ğŸ“ í´ë” ë‚´ ì „ì²´ íŒŒì¼ ê°œìˆ˜: {len(all_files)}ê°œ")
                else:
                    st.error(f"âŒ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {abs_path}")
                st.session_state.last_report_content = ""
                st.session_state.report_chat_history = []
                
                with st.spinner(f"AI ì• ë„ë¦¬ìŠ¤íŠ¸ê°€ {r_days}ì¼ì¹˜ ë°ì´í„°ë¥¼ í†µí•© ë¶„ì„ ì¤‘..."):
                    # [A] ê³¼ê±° ë§¥ë½ ë¡œë“œ
                    historical_context = load_historical_contexts()
                    extended_days = r_days + 2

# [C] ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ (r_days ì ìš©)
                    raw_news = load_pending_files("ì¼ì£¼ì¼")
                    if not raw_news:
                        st.error(f"ğŸ“ íŒŒì¼ {len(os.listdir(PENDING_PATH))}ê°œ ì¤‘ ìœ íš¨í•œ í˜•ì‹ì´ ì—†ìŠµë‹ˆë‹¤.")
                        st.stop()
                    
                    now = datetime.now()
                    # ì£¼ë§(í† , ì¼)ì´ë‚˜ ì›”ìš”ì¼ ì•„ì¹¨ì—ëŠ” ê¸ˆìš”ì¼(3ì¼ ì „) ë°ì´í„°ê¹Œì§€ í¬í•¨
                    lookback_days = 3 if now.weekday() in [5, 6, 0] else 2           
                    news_target_dt = now - timedelta(days=lookback_days)
                    
                    recent_news = [n for n in raw_news if n['pub_dt'].replace(tzinfo=None) >= news_target_dt]
                    recent_news.sort(key=lambda x: x['pub_dt'], reverse=True)                    
                   
                    news_limit = data.get("report_news_count", 100)
                    news_items = [f"[{n['pub_dt'].strftime('%m/%d %H:%M')}] {n['title']}" for n in recent_news]
                    
                    for n in recent_news[:news_limit]:
                        # HTML íƒœê·¸ ì œê±° ë° ê°€ë…ì„± ìµœì í™”
                        title = n['title']
                        summary = clean_html(n.get('summary', ''))[:150]
                        time_str = n['pub_dt'].strftime('%Y-%m-%d %H:%M:%S')
    
                        news_items.append(f"[{time_str}] {title}\n   - ìš”ì•½: {summary}")
                    
                    news_context = f"### [ ìµœê·¼ ì£¼ìš” ë‰´ìŠ¤ ë°ì´í„° ]\n" + "\n".join(news_items)

                    # [D] AI ë³´ê³ ì„œ ìƒì„± ë° ì €ì¥
                    council_instruction = data.get("council_prompt", "ë‹¹ì‹ ì€ ì „ë¬¸ ê¸ˆìœµ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.")
                    
                    # ë¶„ì„ ì§€ì¹¨ ê°•í™”: ìˆ«ìì˜ ìš°ì„ ìˆœìœ„ë¥¼ ëª…í™•íˆ í•¨
                    analysis_guideline = (
                        "### [ ìë£Œ ë¶„ì„ ì§€ì¹¨ ]\n" 
                        "1. ì‹œì¥ ìƒíƒœ ì¸ì§€: í˜„ì¬ê°€ ì£¼ë§ì´ë©´ ê°€ì¥ ìµœê·¼ ê±°ë˜ì¼(ê¸ˆìš”ì¼) ì¢…ê°€ë¥¼ í˜„ì¬ê°€ë¡œ ê°„ì£¼í•œë‹¤.\n"
                        "2. ìˆ˜ì¹˜ ì ˆëŒ€ ìš°ì„ : ë‰´ìŠ¤ ì œëª©ì˜ í†¤ë³´ë‹¤ ë‰´ìŠ¤ì— ë‚˜ì˜¨ ë“±ë½ ìˆ˜ì¹˜(+0.55% ë“±)ë¥¼ ìµœìš°ì„  íŒ©íŠ¸ë¡œ ì‚¼ëŠ”ë‹¤.\n"
                        "3. ì¶”ì„¸ì™€ ë°˜ë“± êµ¬ë¶„: ë©°ì¹ ê°„ í•˜ë½í–ˆë”ë¼ë„ ë§ˆì§€ë§‰ ì§€í‘œê°€ ìƒìŠ¹ì´ë©´ 'ë‹¨ê¸° ë°˜ë“± ì„±ê³µ'ìœ¼ë¡œ í•´ì„í•˜ë¼.\n"
                        "4. ì—°ì†ì„± ì›ì¹™: 'ê³¼ê±° ë¶„ì„ ê¸°ë¡'ì—ì„œ ì œì‹œí–ˆë˜ ì£¼ìš” ì „ë§ê³¼ ì˜¤ëŠ˜ 'ì›ì²œ ìˆ˜ê¸‰ ì§€í‘œ'ë¥¼ ë¹„êµí•˜ì—¬, ì˜ˆì¸¡ì´ ì ì¤‘í–ˆëŠ”ì§€ í˜¹ì€ ìƒí™©ì´ ë³€í–ˆëŠ”ì§€ ë°˜ë“œì‹œ ì–¸ê¸‰í•˜ë¼.\n"
                        "5. ì „ëµì  ìˆ˜ì •: ì§€í‘œ ë³€í™”ì— ë”°ë¼ í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘ì´ë‚˜ íˆ¬ì í–‰ë™ ì§€ì¹¨ì„ ìœ ì—°í•˜ê²Œ ì—…ë°ì´íŠ¸í•˜ë¼.\n"
                    )
                    structure_instruction = (
                        "### [ ë³´ê³ ì„œ ì‘ì„± í˜•ì‹ ]\n"
                        "ê° í•­ëª©ì€ ì•„ë˜ì˜ êµ¬ì¡°ë¥¼ ë°˜ë“œì‹œ ì—„ìˆ˜í•˜ì—¬ ì‘ì„±í•˜ë¼:\n"
                        "1. ì‹œí™© ë¸Œë¦¬í•‘: í˜„ì¬ ì‹œì¥ì˜ í•µì‹¬ í…Œë§ˆë¥¼ í•œ ì¤„ ìš”ì•½ í›„ ì „ì²´ì ì¸ ë¶„ìœ„ê¸° ê¸°ìˆ \n"
                        "2. ì£¼ìš” ë‰´ìŠ¤ ë° ì˜¤í”¼ë‹ˆì–¸: ì œê³µëœ ë‰´ìŠ¤ ì¤‘ ì‹œì¥ ì˜í–¥ë ¥ì´ í° ë°œì–¸ì´ë‚˜ ì‚¬ê±´ ì¸ìš©\n"
                        "3. ê±°ì‹œê²½ì œ ë¶„ì„: í™˜ìœ¨, ê¸ˆë¦¬, ìˆ˜ê¸‰ ì§€í‘œë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ë§¤í¬ë¡œ í™˜ê²½ ì§„ë‹¨\n"
                        "4. ìì‚°ë³„ ë¶„ì„: ì£¼ì‹(êµ­ë‚´/ì™¸), ì±„ê¶Œ, ê°€ìƒìì‚°, ì›ìì¬ë¥¼ 5ì  ì²™ë„ë¡œ í‰ê°€\n"
                        "5. ì‚°ì—…ë³„ ë¶„ì„: ë°˜ë„ì²´, ê¸ˆìœµ, ì—ë„ˆì§€ ë“± ì£¼ìš” ì„¹í„°ë¥¼ 5ì  ì²™ë„ë¡œ í‰ê°€\n"
                        "6. ì£¼ë ¥/ë¯¸ë˜ ì‚°ì—… ì „ë§: í˜„ì¬ ì£¼ë„ì£¼ì˜ ì§€ì† ê°€ëŠ¥ì„±ê³¼ ìƒˆë¡­ê²Œ ë¶€ê°ë˜ëŠ” ë¯¸ë˜ ë¨¹ê±°ë¦¬ ë¶„ì„\n"
                        "7. ë¦¬ìŠ¤í¬ ë¶„ì„: í˜„ì¬ ì‹œì¥ì˜ ìµœëŒ€ ë‡Œê´€ ë° ì ì¬ì  ìœ„í—˜ ìš”ì†Œ 2~3ê°€ì§€ ì§€ì \n"
                        "8. í¬íŠ¸í´ë¦¬ì˜¤ ë° ì „ëµ: êµ¬ì²´ì ì¸ ìì‚° ë°°ë¶„ ë¹„ì¤‘(%)ê³¼ ì‚¬ë ¹ê´€ì„ ìœ„í•œ íˆ¬ì í–‰ë™ ì§€ì¹¨ í•˜ë‹¬\n"
                        "9. ìˆ˜ì¹˜ ê¸°ë¡: ë‹¤ìŒ ë³´ê³ ì„œì—ì„œ ì°¸ê³ í•˜ê²Œ ë‰´ìŠ¤ì—ì„œ ìˆ˜ì§‘í•œ ê²½ì œì§€í‘œë¥¼ ë‚ ì§œì™€ í•¨ê»˜ ê¸°ë¡\n"
                    )
                    
                    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±: ì§€í‘œ(Fact)ë¥¼ ë§ˆì§€ë§‰ì— ë°°ì¹˜í•˜ì—¬ ê°•ì¡°
                    full_instruction = (
                        f"ë‹¹ì‹ ì€ {council_instruction}\n"
                        f"í˜„ì¬ ì‹œê°: {now.strftime('%Y-%m-%d %H:%M:%S')}\n\n"
                        f"{analysis_guideline}\n\n"
                        f"--- [ 1. ê³¼ê±° ë¶„ì„ ê¸°ë¡ ] ---\n{historical_context}\n\n"
                        f"--- [ 2. ë¶„ì„ ëŒ€ìƒ ë‰´ìŠ¤ ë°ì´í„° ] ---\n{news_context}\n\n"
                        f"{structure_instruction}\n"
                        f"**ì£¼ì˜: ë°˜ë“œì‹œ ìœ„ ë‰´ìŠ¤ ë°ì´í„°ì— ëª…ì‹œëœ ìˆ˜ì¹˜ì™€ ì‚¬ê±´ì„ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ë¼.**"
                    )
                    
                    # ì‹¤ì œ ë¦¬í¬íŠ¸ ìƒì„± (ë‰´ìŠ¤ ë³¸ë¬¸ì€ contentë¡œ ì „ë‹¬)
                    report = get_ai_summary(
                        title=f"{date.today()} {r_type.upper()} ë³´ê³ ì„œ", 
                        content=news_context, 
                        system_instruction=full_instruction, 
                        role="analyst"
                    )
                    
                    save_report_to_file(report, r_type)
                    st.session_state.last_report_content = report
                    st.rerun()

    # 3. ê²°ê³¼ ì¶œë ¥ ë° ëŒ€í™”ì°½ (í•˜ë‹¨ ê³µí†µ)
    if st.session_state.last_report_content:
        st.divider()
        st.markdown("#### ğŸ“Š íˆ¬ì ì „ëµ ë¦¬í¬íŠ¸ ë³¸ë¬¸")
        with st.container(border=True):
            st.markdown(st.session_state.last_report_content)

        # ì§ˆì˜ì‘ë‹µ ë‚´ì—­
        for message in st.session_state.report_chat_history:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

# ì‹¤ì‹œê°„ ì±„íŒ… ì…ë ¥
        if chat_input := st.chat_input("ë³´ê³ ì„œ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”."):
            st.session_state.report_chat_history.append({"role": "user", "content": chat_input})
            
            # 1. í˜„ì¬ ì‹œê°„ ë° ìš”ì¼ ì •ë³´ ìƒì„±
            now = get_now_kst()
            days = ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼']
            current_time_info = f"{now.strftime('%Y-%m-%d %H:%M:%S')} ({days[now.weekday()]}ìš”ì¼)"
            
            # 2. í˜ë¥´ì†Œë‚˜ ë° ì‹œê°„ ì •ë³´ê°€ í¬í•¨ëœ ì‹œìŠ¤í…œ ì»¨í…ìŠ¤íŠ¸
            chat_context = (
                f"ë‹¹ì‹ ì€ ì „ë¬¸ ê¸ˆìœµ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.\n"
                f"ğŸ•’ [í˜„ì¬ ì‹œê°]: {current_time_info}\n"                
                f"ğŸ“ [ë³´ê³ ì„œ ë³¸ë¬¸]:\n{st.session_state.last_report_content}\n\n"
                f"ì§ˆë¬¸ì— ë‹µí•  ë•Œ ë°˜ë“œì‹œ í˜„ì¬ ì‹œê°(íœ´ì¥ ì—¬ë¶€ ë“±)ì„ ê³ ë ¤í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”."
            )
            
            response = get_ai_summary(title="ì§ˆì˜", content=chat_input, system_instruction=chat_context, role="analyst")
            st.session_state.report_chat_history.append({"role": "assistant", "content": response})
            st.rerun()
# ğŸ¯ 1. ì„¸ì…˜ì—ì„œ ë³´ê³ ì„œ ë³¸ë¬¸ ê°€ì ¸ì˜¤ê¸°
    report_to_download = st.session_state.get('last_report_content', "ì•„ì§ ìƒì„±ëœ ë³´ê³ ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")

    def create_pdf_data(text):
        from fpdf import FPDF
        pdf = FPDF()
        pdf.add_page()
        
        # ğŸ¯ í°íŠ¸ ë“±ë¡ ë° ì„¤ì • (ìœ ë‹ˆì½”ë“œ ëŒ€ì‘)
        try:
            # run.shì—ì„œ ë‹¤ìš´ë¡œë“œí•œ ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤.
            pdf.add_font("Nanum", "", "/app/fonts/NanumGothic.ttf")
            pdf.set_font("Nanum", size=14)
        except Exception as e:
            # í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í°íŠ¸ë¡œ í›„í‡´ (ê¸€ìëŠ” ê¹¨ì§€ê² ì§€ë§Œ ì—ëŸ¬ëŠ” ì•ˆ ë‚¨)
            pdf.set_font("helvetica", size=14)
            print(f"ğŸš¨ í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

        # ğŸ¯ ì‹¤ì œ ë³´ê³ ì„œ ë³¸ë¬¸ ì‘ì„± (í•œê¸€ ê·¸ëŒ€ë¡œ ì£¼ì…)
        pdf.multi_cell(0, 10, text=text)
        
        return bytes(pdf.output())

    # --- ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ë¶€ë¶„ ---
    try:
        import datetime
        current_date_str = datetime.datetime.now().strftime('%Y%m%d')
        
        # ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ìœ„ í•¨ìˆ˜ê°€ ì‹¤í–‰ë˜ì–´ bytes ë°ì´í„°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        st.download_button(
            label="ğŸ“¥ í˜„ì¬ ë³´ê³ ì„œ PDF ë‹¤ìš´ë¡œë“œ",
            data=create_pdf_data(report_to_download),
            file_name=f"Report_{current_date_str}.pdf",
            mime="application/pdf",
            use_container_width=True
        )
    except Exception as e:
        st.error(f"ğŸš¨ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ìƒì„± ì‹¤íŒ¨: {e}")
        
    # 4. ë¶„ì„ ì§€ì¹¨ ì„¤ì • (í•˜ë‹¨ expander)
    with st.expander("âš™ï¸ ë¶„ì„ ì§€ì¹¨ ìˆ˜ì •"):
        council_instr = data.get("council_prompt", "")
        new_instr = st.text_area("ì§€ì¹¨ ë‚´ìš©", value=council_instr, height=150)
        if st.button("ğŸ’¾ ì§€ì¹¨ ì €ì¥", width='stretch'):
            data["council_prompt"] = new_instr
            save_data(data)
            st.success("ì €ì¥ ì™„ë£Œ")











