import streamlit as st
import pandas as pd
import json
import os
import feedparser
import re
import requests
from datetime import datetime, timedelta, date
from bs4 import BeautifulSoup
import time
import math

# --- 1. ê²½ë¡œ ë° ì„¤ì • ë¡œë“œ ---
CONFIG_PATH = "/share/ai_analyst/rss_config.json"
PENDING_PATH = "/share/ai_analyst/pending"
OPTIONS_PATH = "/data/options.json"

def load_addon_config():
    if os.path.exists(OPTIONS_PATH):
        try:
            with open(OPTIONS_PATH, "r", encoding='utf-8') as f:
                return json.load(f)
        except: pass
    return {}

def load_data():
    if os.path.exists(CONFIG_PATH):
        try:
            with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
                return json.load(f)
        except: pass
    return {"feeds": [], "update_interval": 10}
# ê¸°ì¡´ ë³€ìˆ˜ ì„ ì–¸ ìœ ì§€ 
config = load_addon_config() 
data = load_data()

# LLM ê´€ë ¨ ë³€ìˆ˜ (HA ì˜µì…˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°) 
desktop_ip = data.get("desktop_ip")
llm_api_port = data.get("llm_api_port")
ai_model = data.get("ai_model")

# --- 2. ë‰´ìŠ¤ ì²˜ë¦¬ í•µì‹¬ í•¨ìˆ˜ ---
# --- [ìˆ˜ì •] load_data í•¨ìˆ˜: ì´ˆê¸° ì‹¤í–‰ ì‹œ ê¸°ë³¸ê°’ ë³´ì¥ ---
def load_data():
    default_structure = {
        "feeds": [], 
        "update_interval": 10, 
        "desktop_ip": "192.168.1.2",
        "llm_api_port": "1234",
        "ai_model": "openai/gpt-oss-20b",
        "ai_prompt": "ë‹¹ì‹ ì€ ì „ë¬¸ ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤...",
        "retention_days": 7
    }
    if os.path.exists(CONFIG_PATH):
        try:
            with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
                loaded_data = json.load(f)
                for key, value in default_structure.items():
                    if key not in loaded_data: loaded_data[key] = value
                return loaded_data
        except: pass
    return default_structure

def save_data(data):
    os.makedirs(os.path.dirname(CONFIG_PATH), exist_ok=True)
    with open(CONFIG_PATH, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


# app.py ë‚´ì˜ is_filtered í•¨ìˆ˜ë¥¼ ì´ ë‚´ìš©ìœ¼ë¡œ êµì²´í•˜ì„¸ìš”.
def is_filtered(title, summary, g_inc, g_exc, l_inc="", l_exc=""):
    # ë³€ìˆ˜ ë³´ì¡´: ì œëª©(title) ê¸°ì¤€ í•„í„°ë§
    text = title.lower().strip()
    
    # 1. ì œì™¸ í•„í„°: ì „ì—­/ê°œë³„ ì œì™¸ì–´ ì¤‘ í•˜ë‚˜ë¼ë„ ì œëª©ì— ìˆìœ¼ë©´ ì¦‰ì‹œ íƒˆë½
    exc_tags = [t.strip().lower() for t in (g_exc + "," + l_exc).split(",") if t.strip()]
    if any(t in text for t in exc_tags): 
        return False
    
    # 2. ì „ì—­ í¬í•¨ì–´: ê°’ì´ ì„¤ì •ëœ ê²½ìš°ì—ë§Œ ì œëª©ì— í•´ë‹¹ ë‹¨ì–´ê°€ ìˆì–´ì•¼ í†µê³¼
    g_inc_tags = [t.strip().lower() for t in g_inc.split(",") if t.strip()]
    if g_inc_tags and not any(t in text for t in g_inc_tags):
        return False
        
    # 3. ê°œë³„ í¬í•¨ì–´: ê°’ì´ ì„¤ì •ëœ ê²½ìš°ì—ë§Œ ì œëª©ì— í•´ë‹¹ ë‹¨ì–´ê°€ ìˆì–´ì•¼ í†µê³¼
    l_inc_tags = [t.strip().lower() for t in l_inc.split(",") if t.strip()]
    if l_inc_tags and not any(t in text for t in l_inc_tags):
        return False
    
    return True

def get_ai_summary(title, content, system_instruction=None):
    # ì „ì—­ ë³€ìˆ˜ê°€ ì•„ë‹Œ ì‹¤ì‹œê°„ data ê°’ì„ ì‚¬ìš©í•˜ì—¬ 'ì €ì¥' ì¦‰ì‹œ ë°˜ì˜ë˜ê²Œ í•¨
    target_ip = data.get("desktop_ip")
    target_port = data.get("llm_api_port")
    target_model = data.get("ai_model")
    
    url = f"http://{target_ip}:{target_port}/v1/chat/completions"
    
    if system_instruction:
        final_role = system_instruction
    else:
        final_role = data.get("ai_prompt", "ì „ë¬¸ íˆ¬ì ë¶„ì„ê°€ì…ë‹ˆë‹¤.")

    payload = {
        "model": target_model,
        "messages": [
            {"role": "system", "content": final_role},
            {"role": "user", "content": f"ì œëª©: {title}\në³¸ë¬¸: {content}"}
        ],
        "temperature": 0.3
    }
    
    try:
        resp = requests.post(url, json=payload, timeout=120)
        resp.raise_for_status()
        return resp.json()['choices'][0]['message']['content']
    except Exception as e:
        return f"âŒ AI ì„œë²„ ì—°ê²° ì‹¤íŒ¨ ({target_ip}:{target_port}): {str(e)}"
    
@st.dialog("ğŸ“Š AI ì •ë°€ ë¶„ì„ ë¦¬í¬íŠ¸")
def show_analysis_dialog(title, summary_text):
    # ì°½ì´ ì—´ë¦¬ìë§ˆì ë°”ë¡œ ë¶„ì„ ì‹œì‘
    with st.spinner("AIê°€ ë‰´ìŠ¤ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        # ê¸°ì¡´ ë³€ìˆ˜ëª… config, dataë¥¼ ì‚¬ìš©í•˜ì—¬ AI í˜¸ì¶œ
        # ì„¤ì •(data)ì— ì €ì¥ëœ ai_promptë¥¼ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©
        analysis = get_ai_summary(title, summary_text)
    
    st.markdown(f"### {title}")
    st.divider()
    st.markdown(analysis)
    st.divider()
    
    # í•˜ë‹¨ì— ì›ë¬¸ ìš”ì•½ë³¸ ì°¸ê³ ìš©ìœ¼ë¡œ ë°°ì¹˜
    with st.expander("ê¸°ì‚¬ ì›ë¬¸ ìš”ì•½ ë³´ê¸°"):
        st.write(summary_text)
    st.caption(f"ğŸ¤– ëª¨ë¸: {config.get('ai_model')} | ë¶„ì„ ì£¼ê´€: AI Analyst")

def check_filters(title, include_str, exclude_str):
    title = title.lower().strip()
    if exclude_str:
        exc_tags = [t.strip().lower() for t in exclude_str.split(",") if t.strip()]
        if any(t in title for t in exc_tags): return False
    if include_str:
        inc_tags = [t.strip().lower() for t in include_str.split(",") if t.strip()]
        if not any(t in title for t in inc_tags): return False
    return True

def clean_html(raw_html):
    if not raw_html: return "ìš”ì•½ ë‚´ìš© ì—†ìŒ"
    soup = BeautifulSoup(raw_html, "html.parser")
    for s in soup(['style', 'script', 'span']): s.decompose()
    return re.sub(r'\s+', ' ', soup.get_text()).strip()

def parse_rss_date(date_str):
    try:
        p = feedparser._parse_date(date_str)
        return datetime.fromtimestamp(time.mktime(p))
    except: return datetime.now()

def load_pending_files(range_type, target_feed=None):
    news_list = []
    if not os.path.exists(PENDING_PATH): return news_list
    today_date = date.today()
    one_week_ago = datetime.now() - timedelta(days=7)
    for filename in os.listdir(PENDING_PATH):
        if filename.endswith(".txt"):
            try:
                with open(os.path.join(PENDING_PATH, filename), 'r', encoding='utf-8') as f:
                    lines = f.read().splitlines()
                    title = lines[0].replace("ì œëª©: ", "")
                    link = lines[1].replace("ë§í¬: ", "")
                    pub_str = lines[2].replace("ë‚ ì§œ: ", "")
                    summary = "\n".join(lines[3:]).replace("ìš”ì•½: ", "")
                    pub_dt = parse_rss_date(pub_str)
                    if range_type == "ì˜¤ëŠ˜" and pub_dt.date() != today_date: continue
                    if range_type == "ì¼ì£¼ì¼" and pub_dt < one_week_ago: continue
                    if target_feed:
                        if not check_filters(title, target_feed.get('include', ""), target_feed.get('exclude', "")): continue
                    news_list.append({"title": title, "link": link, "published": pub_str, "summary": summary, "pub_dt": pub_dt, "source": "ì €ì¥ëœ ë°ì´í„°"})
            except: continue
    news_list.sort(key=lambda x: x['pub_dt'], reverse=True)
    return news_list
    
def save_report_to_file(content, section_name):
    # ë³´ê³ ì„œ ì €ì¥ìš© í´ë” ìƒì„±
    report_dir = "/share/ai_analyst/reports"
    os.makedirs(report_dir, exist_ok=True)
    
    # íŒŒì¼ëª… ìƒì„±: 2026-01-31_2330_ì¢…í•©ë¶„ì„.txt
    timestamp = datetime.now().strftime("%Y-%m-%d_%H%M")
    filename = f"{timestamp}_{section_name.replace(' ', '_')}.txt"
    filepath = os.path.join(report_dir, filename)
    
    with open(filepath, "w", encoding="utf-8") as f:
        f.write(content)
    return filepath
    
# --- 3. UI ë° CSS ì„¤ì • ---
st.set_page_config(page_title="AI Analyst", layout="wide")

st.markdown("""
    <style>
    [data-testid="stPopoverBody"] { width: 170px !important; padding: 10px !important; }
    [data-testid="stPopoverBody"] button { padding: 2px 5px !important; margin-bottom: 2px !important; height: auto !important; font-size: 14px !important; }
    [data-testid="stSidebar"] { display: none; }
    [data-testid="stMetricValue"] { font-size: 28px !important; }
    </style>
    """, unsafe_allow_html=True)

data = load_data()
if 'active_menu' not in st.session_state: st.session_state.active_menu = "ë‰´ìŠ¤"
if 'current_feed_idx' not in st.session_state: st.session_state.current_feed_idx = "all"
if 'page_number' not in st.session_state: st.session_state.page_number = 1

# --- 4. ìµœìƒë‹¨ ëŒ€ë©”ë‰´ ---
st.title("ğŸ¤– AI Analyst System")
m_cols = st.columns(3)
menu_items = [("ğŸ“¡ ë‰´ìŠ¤ ìŠ¤íŠ¸ë¦¬ë°", "ë‰´ìŠ¤"), ("ğŸ›ï¸ AI íˆ¬ì ë³´ê³ ì„œ", "AI"), ("âš™ï¸ ì„¤ì •", "ì„¤ì •")]

for i, (label, m_key) in enumerate(menu_items):
    if m_cols[i].button(label, use_container_width=True, type="primary" if st.session_state.active_menu == m_key else "secondary"):
        st.session_state.active_menu = m_key; st.rerun()

st.divider()

# --- 5. ë©”ë‰´ë³„ ë³¸ë¬¸ í™”ë©´ êµ¬ì„± ---

if st.session_state.active_menu == "ì„¤ì •":
    st.subheader("âš™ï¸ ì‹œìŠ¤í…œ ë° AI ì„œë²„ ì„¤ì •")
    st.info("ğŸ’¡ ë³´ì•ˆì´ í•„ìš”í•œ AI ì„œë²„ ë° DB ì„¤ì •ì€ Home Assistant ì• ë“œì˜¨ êµ¬ì„± íƒ­ì—ì„œ ìˆ˜ì •í•˜ì„¸ìš”.")
    
# AI ì„œë²„ ì„¤ì • ì„¹ì…˜ ì¶”ê°€
    with st.expander("ğŸ¤– ë¡œì»¬ AI ì„œë²„ ì„¤ì •", expanded=True):
        col_ip, col_port = st.columns([0.7, 0.3])
        new_ip = col_ip.text_input("ë°ìŠ¤í¬íƒ‘ IP ì£¼ì†Œ", value=data.get("desktop_ip", desktop_ip))
        new_port = col_port.text_input("LLM API í¬íŠ¸", value=data.get("llm_api_port", llm_api_port))
        new_model = st.text_input("ì‚¬ìš©í•  AI ëª¨ë¸ëª…", value=data.get("ai_model", ai_model))        
        
        if st.button("ğŸš€ AI ì„œë²„ ì„¤ì • ì €ì¥", use_container_width=True):
            data.update({
                "desktop_ip": new_ip,
                "llm_api_port": new_port,
                "ai_model": new_model
            })
            save_data(data)
            st.success("âœ… AI ì„œë²„ ì ‘ì† ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.toast("AI ì„¤ì • ë°˜ì˜ ì™„ë£Œ")

    st.write("") # ê°„ê²© ì¡°ì ˆ
    
   
# --- 2. ë‰´ìŠ¤ ìŠ¤íŠ¸ë¦¬ë° ì„¤ì • ì„¹ì…˜ ---
    with st.container(border=True):
        st.markdown("#### ğŸ“¡ ë‰´ìŠ¤ ìŠ¤íŠ¸ë¦¬ë° ì„¤ì •")
        
        # AI ë¶„ì„ í”„ë¡¬í”„íŠ¸
        default_prompt = "ì „ë¬¸ íˆ¬ì ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‰´ìŠ¤ì˜ í•µì‹¬ í¬ì¸íŠ¸ 3ê°€ì§€ë¥¼ ë¶„ì„í•˜ì„¸ìš”."
        new_prompt = st.text_area(
            "AI ë¶„ì„ ì‹œìŠ¤í…œ ì§€ì¹¨ (System Prompt)", 
            value=data.get("ai_prompt", default_prompt),
            height=150
        )
        
        col_ret, col_int = st.columns(2)
        new_retention = col_ret.slider("ë‰´ìŠ¤ íŒŒì¼ ë³´ê´€ ê¸°ê°„ (ì¼)", 1, 30, data.get("retention_days", 7))
        new_interval = col_int.number_input("RSS ìˆ˜ì§‘ ì£¼ê¸° (ë¶„)", 1, value=data.get("update_interval", 10))
        
        if st.button("ğŸ’¾ ë‰´ìŠ¤ ìŠ¤íŠ¸ë¦¬ë° ì„¤ì • ì €ì¥", use_container_width=True, type="primary"):
            data.update({
                "ai_prompt": new_prompt,
                "retention_days": new_retention,
                "update_interval": new_interval
            })
            save_data(data)
            st.success("âœ… ë‰´ìŠ¤ ìˆ˜ì§‘ ë° í”„ë¡¬í”„íŠ¸ ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.toast("ë‰´ìŠ¤ ì„¤ì • ë°˜ì˜ ì™„ë£Œ")

    st.write("") # ê°„ê²© ì¡°ì ˆ

    # --- 3. íˆ¬ì ë³´ê³ ì„œ ì„¤ì • ì„¹ì…˜ ---
    with st.container(border=True):
        st.markdown("#### ğŸ“‘ AI íˆ¬ì ë³´ê³ ì„œ ì„¤ì •")
        report_days = st.number_input(
            "ë¶„ì„ ë°ì´í„° ë²”ìœ„ (ì¼ ë‹¨ìœ„)", 
            min_value=1, 
            max_value=data.get("retention_days", 30), 
            value=data.get("report_days", 3)
        )

        if st.button("ğŸ“Š ë³´ê³ ì„œ ì„¤ì • ì €ì¥", use_container_width=True):
            data["report_days"] = report_days
            save_data(data)
            st.success("âœ… íˆ¬ì ë³´ê³ ì„œ ë²”ìœ„ ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # --- 4. InfluxDB ì •ë³´ (ì½ê¸° ì „ìš©) ---
    with st.expander("â„¹ï¸ ë°ì´í„°ë² ì´ìŠ¤(InfluxDB) ì—°ê²° ì •ë³´"):
        st.info("ë°ì´í„°ë² ì´ìŠ¤ ë³´ì•ˆ ì„¤ì •ì€ HA ì• ë“œì˜¨ì˜ 'êµ¬ì„±(Configuration)' íƒ­ì—ì„œë§Œ ìˆ˜ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        st.code(f"URL: {config.get('influx_url')}\nOrg: home_assistant\nBucket: financial_data")
        


# [2. ë‰´ìŠ¤ ìŠ¤íŠ¸ë¦¬ë°]
elif st.session_state.active_menu == "ë‰´ìŠ¤":    
    col_side, col_main = st.columns([0.22, 0.78])
    
    with col_side:
        st.markdown("#### ğŸ“Œ RSS ê´€ë¦¬")
        # ì „ì²´ ë³´ê¸° ë²„íŠ¼
        if st.button("ğŸ  ì „ì²´ ë³´ê¸°", use_container_width=True, type="primary" if st.session_state.current_feed_idx == "all" else "secondary"):
            st.session_state.current_feed_idx = "all"; st.session_state.page_number = 1; st.rerun()
        
# ê° í”¼ë“œ ë¦¬ìŠ¤íŠ¸ ë° ê´€ë¦¬ ë©”ë‰´
        for i, f in enumerate(data.get('feeds', [])):
            btn_col, pop_col = st.columns([0.8, 0.2])
            with btn_col:
                if st.button(f['name'], key=f"f_{i}", use_container_width=True, type="primary" if st.session_state.current_feed_idx == i else "secondary"):
                    st.session_state.current_feed_idx = i; st.session_state.page_number = 1; st.rerun()
            with pop_col:
                # ì•„ì´ì½˜ ì—†ì´ 'ì„¤ì •' í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•˜ê±°ë‚˜ ë” ì‘ê²Œ ì¤„ì¸ íŒì—…
                with st.popover(""):
                    # ì•„ì´ì½˜(âœï¸, ğŸ”, ğŸ—‘ï¸)ì„ ëª¨ë‘ ì œê±°í•˜ê³  í…ìŠ¤íŠ¸ë¡œë§Œ êµ¬ì„±
                    if st.button("í¸ì§‘", key=f"ed_{i}", use_container_width=True):
                        @st.dialog("í”¼ë“œ ìˆ˜ì •")
                        def ed_diag(idx=i):
                            fe = data['feeds'][idx]
                            n = st.text_input("ì´ë¦„", value=fe['name'])
                            u = st.text_input("URL", value=fe['url'])
                            if st.button("ì €ì¥"):
                                data['feeds'][idx].update({"name": n, "url": u}); save_data(data); st.rerun()
                        ed_diag()
                    
                    if st.button("í•„í„°", key=f"fi_{i}", use_container_width=True):
                        @st.dialog("í‚¤ì›Œë“œ í•„í„°")
                        def fi_diag(idx=i):
                            fe = data['feeds'][idx]
                            inc = st.text_area("í¬í•¨ í‚¤ì›Œë“œ", value=fe.get('include', ""))
                            exc = st.text_area("ì œì™¸ í‚¤ì›Œë“œ", value=fe.get('exclude', ""))
                            if st.button("í•„í„° ì ìš©"):
                                data['feeds'][idx].update({"include": inc, "exclude": exc}); save_data(data); st.rerun()
                        fi_diag()
                        
                    if st.button("ì‚­ì œ", key=f"de_{i}", use_container_width=True):
                        data['feeds'].pop(i); save_data(data); st.rerun()
        
        st.divider()
        # [ë³µêµ¬] í”¼ë“œ ì¶”ê°€ ë²„íŠ¼
        if st.button("â• ìƒˆ RSS ì¶”ê°€", use_container_width=True):
            @st.dialog("ìƒˆ RSS ë“±ë¡")
            def add_diag():
                n = st.text_input("í”¼ë“œ ì´ë¦„ (ì˜ˆ: ì—°í•©ë‰´ìŠ¤)")
                u = st.text_input("RSS URL ì£¼ì†Œ")
                if st.button("ë“±ë¡ ì™„ë£Œ"):
                    data['feeds'].append({"name": n, "url": u, "include": "", "exclude": ""})
                    save_data(data); st.rerun()
            add_diag()
    with col_side:
        # [ì¶”ê°€] ì „ì—­ í•„í„° ì„¤ì • êµ¬ì—­
        with st.expander("ğŸŒ ì „ì—­ í•„í„° ì„¤ì •", expanded=False):
            g_inc = st.text_area("ì „ì—­ í¬í•¨ í‚¤ì›Œë“œ", value=data.get("global_include", ""), help="ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„")
            g_exc = st.text_area("ì „ì—­ ì œì™¸ í‚¤ì›Œë“œ", value=data.get("global_exclude", ""), help="ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„")
            if st.button("ì „ì—­ í•„í„° ì €ì¥", use_container_width=True):
                data.update({"global_include": g_inc, "global_exclude": g_exc})
                save_data(data)
                st.toast("ì „ì—­ í•„í„°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")

    with col_main:
        full_list = []
        target = data.get('feeds', []) if st.session_state.current_feed_idx == "all" else [data['feeds'][st.session_state.current_feed_idx]]
        
        for f_info in target:
            try:
                parsed = feedparser.parse(f_info['url'])
                for e in parsed.entries:
                    # ê°•í™”ëœ ì œëª© í•„í„° ì ìš© (ë²„ê·¸ ìˆ˜ì •ë¨)
                    if is_filtered(e.title, e.get('summary', ''), 
                                   data.get("global_include", ""), data.get("global_exclude", ""),
                                   f_info.get('include', ""), f_info.get('exclude', "")):
                        e['source'] = f_info['name']
                        full_list.append(e)
            except: continue
            
        full_list.sort(key=lambda x: x.get('published_parsed', 0), reverse=True)
        
        if full_list:
            # 1. í˜ì´ì§€ë„¤ì´ì…˜ ë³€ìˆ˜ ì •ì˜
            items_per_page = 10
            total_pages = math.ceil(len(full_list) / items_per_page)
            
            # 2. í˜„ì¬ í˜ì´ì§€ ìŠ¬ë¼ì´ì‹± ê³„ì‚°
            start_idx = (st.session_state.page_number - 1) * items_per_page
            end_idx = start_idx + items_per_page
            
            # 3. ë‰´ìŠ¤ ê¸°ì‚¬ ë°˜ë³µ ì¶œë ¥
            for entry in full_list[start_idx:end_idx]:
                with st.container(border=True):
                    st.caption(f"ğŸ“ {entry.get('source')} | {entry.get('published', '')}")
                    st.markdown(f"#### {entry.get('title')}")
                    
                    cleaned_summary = clean_html(entry.get('summary', ''))
                    st.write(cleaned_summary[:200] + "...")
                    
                    btn_c1, btn_c2 = st.columns([0.2, 0.8])
                    
                    # 1. ì›ë¬¸ ì½ê¸°
                    btn_c1.link_button("ğŸŒ ì›ë¬¸ ì½ê¸°", entry.get('link', '#'), use_container_width=True)
                    
                    # 2. AI ìš”ì•½ ë¶„ì„ (í´ë¦­ ì¦‰ì‹œ ë¶„ì„ íŒì—… ì‹¤í–‰)
                    if btn_c2.button("ğŸ¤– AI ìš”ì•½ ë¶„ì„", key=f"ai_btn_{entry.get('link')}", use_container_width=True):
                        show_analysis_dialog(entry.get('title'), cleaned_summary)

            st.divider()
            
            # --- [ 4. ê°œì„ ëœ í˜ì´ì§€ ë‚´ë¹„ê²Œì´í„° ] ---
            if total_pages > 1:
                # 10ë‹¨ìœ„ ë­‰ì¹˜ ê³„ì‚°
                current_group = (st.session_state.page_number - 1) // 10
                start_page = current_group * 10 + 1
                end_page = min(start_page + 9, total_pages)
                
                # ë²„íŠ¼ ë ˆì´ì•„ì›ƒ (ì´ì „ + ìˆ«ì 10ê°œ + ë‹¤ìŒ)
                nav_cols = st.columns([0.6] + [1] * (end_page - start_page + 1) + [0.6])
                
                # [ < ] ì´ì „ 10ê°œ ë­‰ì¹˜ ì´ë™
                if start_page > 1:
                    if nav_cols[0].button("<", key="prev_group"):
                        st.session_state.page_number = start_page - 1
                        st.rerun()
                
                # ìˆ«ì ë²„íŠ¼ë“¤
                for i, page_idx in enumerate(range(start_page, end_page + 1)):
                    if nav_cols[i+1].button(
                        str(page_idx), 
                        key=f"page_{page_idx}",
                        type="primary" if st.session_state.page_number == page_idx else "secondary",
                        use_container_width=True
                    ):
                        st.session_state.page_number = page_idx
                        st.rerun()
                
                # [ > ] ë‹¤ìŒ 10ê°œ ë­‰ì¹˜ ì´ë™
                if end_page < total_pages:
                    if nav_cols[-1].button(">", key="next_group"):
                        st.session_state.page_number = end_page + 1
                        st.rerun()
        else:
            st.warning("ğŸ“¡ í‘œì‹œí•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

# [3. AI íˆ¬ì ë³´ê³ ì„œ]
elif st.session_state.active_menu == "AI":
    st.subheader("ğŸ“‘ AI íˆ¬ì ë³´ê³ ì„œ")
    
    # 1. ì„¸ì…˜ ë° ê²½ë¡œ ì„¤ì •
    if "report_chat_history" not in st.session_state:
        st.session_state.report_chat_history = []
    if "last_report_content" not in st.session_state:
        st.session_state.last_report_content = ""

    REPORT_DIR = "/share/ai_analyst/reports"
    os.makedirs(REPORT_DIR, exist_ok=True)

    # [ì‹ ê·œ ë¡œì§] ì„¸ì…˜ì— ë³´ê³ ì„œê°€ ì—†ìœ¼ë©´ ì €ì¥ëœ íŒŒì¼ ì¤‘ ê°€ì¥ ìµœì‹  ê²ƒ ë¡œë“œ
    if not st.session_state.last_report_content:
        report_files = sorted([f for f in os.listdir(REPORT_DIR) if f.startswith("Report_")], reverse=True)
        if report_files:
            latest_file = report_files[0]
            try:
                with open(os.path.join(REPORT_DIR, latest_file), "r", encoding="utf-8") as f:
                    st.session_state.last_report_content = f.read()
                print(f"[{datetime.now().strftime('%H:%M:%S')}] [INFO] ê¸°ì¡´ ë³´ê³ ì„œ ìë™ ë¡œë“œ: {latest_file}")
            except Exception as e:
                print(f"[ERROR] íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")

    # ì„¤ì •ê°’ ë¡œë“œ
    analysis_range = data.get("report_days", 3)
    council_instruction = data.get("council_prompt", "ì‹œë‹ˆì–´ íˆ¬ì ì „ëµê°€ë¡œì„œ ì¢…í•© ì˜ê²¬ì„ ì œì‹œí•˜ë¼.")

    # 2. ë¶„ì„ ì‹¤í–‰ ì„¹ì…˜
    with st.container(border=True):
        st.markdown("### ğŸ›ï¸ ì‹œì¥ ì¢…í•© ì˜ê²¬ ë¶„ì„")
        
        # ë¶„ì„ ì§€ì¹¨ ì…ë ¥ ì˜ì—­
        new_instruction = st.text_area(
            "ë¶„ì„ ì§€ì¹¨ ìˆ˜ì •", 
            value=council_instruction, 
            height=150, 
            key="report_instr_area"
        )
        
        # [ì¶”ê°€] ë¶„ì„ ì§€ì¹¨ ì €ì¥ ë²„íŠ¼
        if st.button("ğŸ’¾ ë¶„ì„ ì§€ì¹¨ ì €ì¥", use_container_width=True):
            data["council_prompt"] = new_instruction
            save_data(data) # ì§€ì¹¨ì„ rss_config.jsonì— ì¦‰ì‹œ ë°˜ì˜
            st.success("âœ… ë¶„ì„ ì§€ì¹¨ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.toast("ì§€ì¹¨ ì €ì¥ ì™„ë£Œ")

        st.divider() # ì‹œê°ì  êµ¬ë¶„ì„  ì¶”ê°€

        # ë³´ê³ ì„œ ìƒì„± ë²„íŠ¼ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        if st.button("ğŸš€ ìƒˆ ì¢…í•© AI ë³´ê³ ì„œ ìƒì„±", type="primary", use_container_width=True):
            # ìƒˆ ë³´ê³ ì„œ ì‘ì„± ì‹œì‘ ì‹œ ê¸°ì¡´ ë°ì´í„° ì´ˆê¸°í™”
            st.session_state.last_report_content = ""
            st.session_state.report_chat_history = []
            
            with st.spinner("ë°ì´í„° í†µí•© ë¶„ì„ ë° ìƒˆ ë³´ê³ ì„œ ì‘ì„± ì¤‘..."):
                # [RAG] ì „ë‚  ë³´ê³ ì„œ ë¡œë“œ (ì–´ì œ ë‚ ì§œ íŒŒì¼ ê²€ìƒ‰)
                yesterday_str = (date.today() - timedelta(days=1)).strftime("%Y-%m-%d")
                yesterday_path = os.path.join(REPORT_DIR, f"Report_{yesterday_str}.txt")
                yesterday_context = ""
                if os.path.exists(yesterday_path):
                    with open(yesterday_path, "r", encoding="utf-8") as f:
                        yesterday_context = f.read()
                
                # [Metrics] InfluxDB ë°ì´í„° ë¡œë“œ
                metric_context = ""
                try:
                    client = InfluxDBClient(url=INFLUX_URL, token=INFLUX_TOKEN, org=INFLUX_ORG)
                    query_api = client.query_api()
                    m_query = f'from(bucket: "{INFLUX_BUCKET}") |> range(start: -24h) |> filter(fn: (r) => r._measurement == "financial_metrics" and r._field == "price") |> last()'
                    tables = query_api.query(m_query)
                    metrics = [f"- {r['symbol']}: {r.get_value():,.2f}" for t in tables for r in t.records]
                    metric_context = "\n".join(metrics)
                except: pass

                # [News] ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ
                raw_news = load_pending_files("ì¼ì£¼ì¼") 
                target_date = datetime.now() - timedelta(days=analysis_range)
                recent_news = [n for n in raw_news if n['pub_dt'] >= target_date]
                news_context = "\n".join([f"- {n['title']}" for n in recent_news[:30]])

                if not news_context:
                    st.warning("ğŸ“¡ ë¶„ì„í•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                    full_instruction = f"{new_instruction}\n\n### [ì°¸ì¡° ë°ì´í„°]\n"
                    if yesterday_context: full_instruction += f"\n- ì „ë‚  ë¶„ì„ ë§¥ë½ í¬í•¨ë¨"
                    if metric_context: full_instruction += f"\n- ì‹¤ì‹œê°„ ì§€í‘œ:\n{metric_context}"

                    # ë³´ê³ ì„œ ìƒì„±
                    report = get_ai_summary(title=f"{date.today()} ì¢…í•© ì „ëµ", content=news_context, system_instruction=full_instruction)
                    st.session_state.last_report_content = report
                    
                    # ì €ì¥ ë° ì •ë¦¬
                    today_str = date.today().strftime("%Y-%m-%d")
                    with open(os.path.join(REPORT_DIR, f"Report_{today_str}.txt"), "w", encoding="utf-8") as f:
                        f.write(report)
                    
                    # 7ì¼ ê²½ê³¼ ì‚­ì œ
                    current_time = time.time()
                    for f in os.listdir(REPORT_DIR):
                        f_p = os.path.join(REPORT_DIR, f)
                        if os.path.isfile(f_p) and (current_time - os.path.getmtime(f_p) > 7 * 86400):
                            os.remove(f_p)
                    
                    st.rerun()

    # 3. ê²°ê³¼ ì¶œë ¥ ë° ëŒ€í™”ì°½
    if st.session_state.last_report_content:
        st.markdown("---")
        st.markdown("#### ğŸ“Š íˆ¬ì ë³´ê³ ì„œ")
        with st.container(border=True):
            st.markdown(st.session_state.last_report_content)

        # ì±„íŒ… ì„¹ì…˜
        if st.session_state.report_chat_history:
            st.markdown("#### ğŸ’¬ ì§ˆì˜ì‘ë‹µ ë‚´ì—­")
            for message in st.session_state.report_chat_history:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

        if chat_input := st.chat_input("ë³´ê³ ì„œ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”."):
            st.session_state.report_chat_history.append({"role": "user", "content": chat_input})
            chat_context = f"ë‹¹ì‹ ì€ ì´ ë³´ê³ ì„œë¥¼ ì‘ì„±í•œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë³´ê³ ì„œ ë‚´ìš©: {st.session_state.last_report_content}"
            response = get_ai_summary(title="ì¶”ê°€ ì§ˆë¬¸", content=chat_input, system_instruction=chat_context)
            st.session_state.report_chat_history.append({"role": "assistant", "content": response})
            st.rerun()

    st.divider()
    st.caption("ğŸ’¾ ìµœê·¼ 7ì¼ê°„ì˜ ë³´ê³ ì„œê°€ ë³´ê´€ë©ë‹ˆë‹¤.")