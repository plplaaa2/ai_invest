import hashlib
from common import *

processed_titles = set()

def save_file(entry, feed_name):
    """ê°œì„ ëœ íƒ€ì„ë¼ì¸ ë³´ì¡´ ì €ì¥ ë°©ì‹ (JSON)"""
    global processed_titles
    
    title = entry.title.strip()
# ğŸ¯ 1. ë°œí–‰ ì‹œê°„ì„ KST(í•œêµ­ í‘œì¤€ì‹œ)ë¡œ ì—„ê²©í•˜ê²Œ ë³€í™˜ [cite: 1, 4]
    if hasattr(entry, 'published_parsed') and entry.published_parsed:
        # UTC ê¸°ë°˜ êµ¬ì¡°ì²´ ì‹œê°„ì„ KST datetime ê°ì²´ë¡œ ë³€í™˜ [cite: 3, 4]
        dt_obj = datetime.fromtimestamp(time.mktime(entry.published_parsed), tz=timezone.utc).astimezone(KST)
    else:
        # ì‹œê°„ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° í˜„ì¬ KST ì‹œê° ì‚¬ìš© 
        dt_obj = get_now_kst()
        
    dt_str = dt_obj.strftime('%Y%m%d_%H%M%S')# íŒŒì¼ëª… ì •ë ¬ìš©
    date_key = dt_obj.strftime('%Y%m%d')     # ì¼ë³„ ì¤‘ë³µ ë¶„ë¦¬ìš©
    pub_dt_str = dt_obj.strftime('%Y-%m-%d %H:%M:%S') # ë°ì´í„° ì €ì¥ìš©
    
    # ğŸ¯ 2. ì¤‘ë³µ ì²´í¬ í‚¤ ê°•í™” (ë‚ ì§œ + ì œëª© 15ì)
    # ì´ì œ ë‚ ì§œê°€ ë‹¤ë¥´ë©´ ê°™ì€ ì œëª©ì´ë¼ë„ ë³„ê°œ ë‰´ìŠ¤ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    clean_key = f"{date_key}_{title.replace(' ', '')[:15]}"
    
    if clean_key in processed_titles:
        return False
    
    # ğŸ¯ 3. íŒŒì¼ëª…ì— ì‹œê°„ ì •ë³´ ì£¼ì… (ì •ë ¬ ìµœì í™”)
    file_hash = hashlib.md5(title.encode()).hexdigest()[:6]
    filename = f"{dt_str}_{file_hash}.json" # JSON í™•ì¥ì ì‚¬ìš©
    filepath = os.path.join(PENDING_PATH, filename)
    
    # ğŸ¯ 4. ë°ì´í„° êµ¬ì¡°í™” (AI ë¶„ì„ìš© ì •ë³´ í™•ì¥)
    news_data = {
        "title": title,
        "pub_dt": pub_dt_str, # [ìˆ˜ì • ì™„ë£Œ]
        "source": feed_name,
        "summary": entry.get('summary', 'ë‚´ìš© ì—†ìŒ'),
        "link": entry.get('link', '')
    }
    
    try:
        os.makedirs(PENDING_PATH, exist_ok=True)
        with open(filepath, "w", encoding='utf-8') as f:
            json.dump(news_data, f, ensure_ascii=False, indent=2)
        processed_titles.add(clean_key)
        return True
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì“°ê¸° ì‹¤íŒ¨: {e}") # ì—ëŸ¬ ë¡œê·¸ë¥¼ ë‚¨ê²¨ì•¼ ê²½ë¡œ ë¬¸ì œë¥¼ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        return False
        
def check_logic(text, inc_list, exc_list):
    """í•„í„°ë§ ë¡œì§: ì œì™¸ì–´ í¬í•¨ ì‹œ íƒˆë½, í¬í•¨ì–´ ì„¤ì • ì‹œ í¬í•¨ë˜ì–´ì•¼ í†µê³¼"""
    text = text.lower()
    if any(x in text for x in exc_list if x):
        return False
    if inc_list:
        if not any(i in text for i in inc_list if i):
            return False
    return True

def cleanup_old_files(retention_days):
    """ì„¤ì •ëœ ê¸°ê°„ë³´ë‹¤ ì˜¤ë˜ëœ íŒŒì¼ ë° ë©”ëª¨ë¦¬ ìºì‹œ ì‚­ì œ"""
    global processed_titles
    if not os.path.exists(PENDING_PATH): return
    
    current_time = time.time()
    seconds_threshold = retention_days * 86400
    deleted_count = 0
    
    for filename in os.listdir(PENDING_PATH):
        file_path = os.path.join(PENDING_PATH, filename)
        if os.path.isfile(file_path) and (filename.endswith(".json") or filename.endswith(".txt")):
            if (current_time - os.path.getmtime(file_path)) > seconds_threshold:
                try:
                    os.remove(file_path)
                    deleted_count += 1
                except: pass
    
    # íŒŒì¼ ì‚­ì œ ì‹œ ë©”ëª¨ë¦¬ ìºì‹œë„ í•¨ê»˜ ë¹„ì›Œ ì‹œìŠ¤í…œì„ ê°€ë³ê²Œ ìœ ì§€
    processed_titles.clear()
    if deleted_count > 0:
        print(f"ğŸ§¹ {deleted_count}ê°œì˜ ë‰´ìŠ¤ íŒŒì¼ì„ ì •ë¦¬í•˜ê³  ì¤‘ë³µ í•„í„°ë¥¼ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")


def generate_auto_report(config_data, r_type="daily"):
    """
    [í†µí•© ë³´ê³ ì„œ ì—”ì§„] - ìœ í˜•ë³„ ë°ì´í„° ì¤€ë¹„ì™€ AI ì—”ì§„ì„ ë¶„ë¦¬í•˜ì—¬ ì‹¤í–‰
    """
    now_kst = get_now_kst()
    now_str = now_kst.strftime("%Y-%m-%d %H:%M:%S")
    print(f"\n[ {now_str} ] ğŸ›ï¸ {r_type.upper()} ë³´ê³ ì„œ ìƒì„± í”„ë¡œì„¸ìŠ¤ ì‹œì‘...")

    # 1. ë³´ê³ ì„œ ìœ í˜•ë³„ ë°ì´í„° ì¤€ë¹„
    if r_type == "daily":
        input_content, report_label = _prepare_daily_report_data(config_data, now_kst)
    else:
        input_content, report_label = _prepare_periodical_report_data(config_data, r_type)

    if not input_content:
        print(f"âš ï¸ [ê²½ê³ ] {r_type.upper()} ë¦¬í¬íŠ¸ ìƒì„±ì„ ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return False

    # 2. AI ì—”ì§„ í˜¸ì¶œ (ë¶„ì„ ë° ì €ì¥)
    return _execute_report_ai_engine(config_data, r_type, report_label, input_content)

def _prepare_daily_report_data(config_data, now_kst):
    """ì¼ê°„ ë³´ê³ ì„œìš© ë°ì´í„° êµ¬ì„± (ë‰´ìŠ¤ í•„í„°ë§ + ì§€í‘œ ë°ì´í„°)"""
    print(f"ğŸ” [STEP 2-D] Daily ë°ì´í„° ìˆ˜ì§‘ ë° ë‰´ìŠ¤ í•„í„°ë§ ì‹œì‘...")
    
    # (1) ì§€í‘œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ìµœê·¼ 7ì¼ ì¶”ì„¸)
    metric_ctx = get_influx_metric_context(7)
    
    # (2) ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ì¤‘ë³µ/ë‚ ì§œ í•„í„°ë§ (ì œê³µëœ ë¡œì§ ì ìš©)
    news_count = config_data.get("report_news_count", 100)
    raw_news_list = []
    seen_keys = set()
    target_date_limit = (now_kst - timedelta(days=3)).date()
    
    if os.path.exists(PENDING_PATH):
        files = sorted([f for f in os.listdir(PENDING_PATH) if f.endswith(".json")], reverse=True)
        parse_fail, filter_fail = 0, 0

        for f_name in files:
            try:
                with open(os.path.join(PENDING_PATH, f_name), "r", encoding="utf-8") as file:
                    news_data = json.load(file)
                    title = news_data.get("title", "").strip()
                    pub_dt_str = news_data.get("pub_dt", "")
                    
                    if not title: continue
                    
                    # ë‚ ì§œ ì²´í¬
                    try:
                        f_dt = datetime.strptime(pub_dt_str, '%Y-%m-%d %H:%M:%S').date()
                    except:
                        f_dt = now_kst.date()

                    if f_dt < target_date_limit:
                        filter_fail += 1
                        continue

                    # ì¤‘ë³µ ì œê±° í‚¤ ìƒì„±
                    clean_key = title.replace("[íŠ¹ì§•ì£¼]", "").replace("[ì†ë³´]", "").replace(" ", "")[:18]
                    if clean_key not in seen_keys:
                        seen_keys.add(clean_key)
                        raw_news_list.append(f"[{pub_dt_str[5:16]}] {title}")
                        
                    if len(raw_news_list) >= news_count:
                        break
            except:
                parse_fail += 1
                continue
        print(f"ğŸ“Š [ê²°ê³¼] ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: ìµœì¢… {len(raw_news_list)}ê°œ (ì œì™¸: {filter_fail}, ì‹¤íŒ¨: {parse_fail})")
    
    news_ctx = f"### [ ê¸ˆì¼ ì£¼ìš” ë‰´ìŠ¤ {len(raw_news_list)}ì„  ]\n" + "\n".join([f"- {t}" for t in raw_news_list])
    
    final_input = f"{metric_ctx}\n\n{news_ctx}"
    return final_input, "ì¼ê°„(Daily)"

def _prepare_periodical_report_data(config_data, r_type):
    """ì£¼ê°„/ì›”ê°„ ë³´ê³ ì„œìš© ë°ì´í„° êµ¬ì„± (ê³¼ê±° ë¦¬í¬íŠ¸ ìš”ì•½)"""
    lookback = 7 if r_type == "weekly" else 30
    label = "ì£¼ê°„(Weekly)" if r_type == "weekly" else "ì›”ê°„(Monthly)"
    print(f"ğŸ—“ï¸ [STEP 2-{r_type[0].upper()}] {label} ëª¨ë“œ: ê³¼ê±° ë¦¬í¬íŠ¸ ìš”ì•½ êµ¬ì„± ì¤‘...")

    # (1) ì§€í‘œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    metric_ctx = get_influx_metric_context(lookback)
    
    # (2) ê³¼ê±° ì¼ê°„ ë¦¬í¬íŠ¸ íŒŒì¼ ì½ê¸°
    daily_dir = os.path.join(REPORT_DIR, "01_daily")
    report_summary = f"### [ ì§€ë‚œ {lookback}ì¼ê°„ì˜ ë¶„ì„ ê¸°ë¡ ìš”ì•½ ]\n"
    
    if os.path.exists(daily_dir):
        files = sorted([f for f in os.listdir(daily_dir) if f.endswith(".txt") and f != "latest.txt"], reverse=True)
        for f_name in files[:lookback]:
            try:
                with open(os.path.join(daily_dir, f_name), 'r', encoding='utf-8') as f:
                    # íŒŒì¼ëª…ê³¼ ë³¸ë¬¸ ì¼ë¶€ ì¶”ì¶œ
                    report_summary += f"\n- {f_name}: {f.read()[:400]}...\n"
            except Exception as e:
                print(f"âš ï¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({f_name}): {e}")
    
    final_input = f"{metric_ctx}\n\n{report_summary}"
    return final_input, label

def _execute_report_ai_engine(config_data, r_type, report_label, input_content):
    """[ê³µí†µ AI ì—”ì§„] ì§€ì¹¨ êµ¬ì„±, AI í˜¸ì¶œ ë° ì €ì¥"""
    now_kst = get_now_kst()
    now_str = now_kst.strftime("%Y-%m-%d %H:%M:%S")
    historical_context = load_historical_contexts() # STEP 1 ë§¥ë½ ë¡œë“œ

    # 1. í”„ë¡¬í”„íŠ¸ ì„¤ì • (ì°¸ì¡°í•˜ì‹  êµ¬ì¡° ì ìš©)
    if r_type == "daily":
        base_prompt = config_data.get("council_prompt", "ë‹¹ì‹ ì€ ì „ëµ ìì‚° ë°°ë¶„ê°€ì…ë‹ˆë‹¤.")
    else:
        base_prompt = (
            f"ë‹¹ì‹ ì€ 'ì „ëµ ìì‚° ë°°ë¶„ê°€'ì…ë‹ˆë‹¤. ì œê³µëœ ë‰´ìŠ¤ì˜ ì§€í‘œ ì¶”ì„¸ì™€ ê³¼ê±° ë¶„ì„ ê¸°ë¡ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ "
            "ë‹¨ê¸°ì  ì†ŒìŒ(Noise)ì„ ì œê±°í•˜ê³  ê±°ì‹œì ì¸ íë¦„(Trend)ì„ ìš”ì•½í•˜ì„¸ìš”."
        )

    analysis_guideline = (
        "### [ ìë£Œ ë¶„ì„ ì§€ì¹¨ ]\n"
        "1. ìˆ˜ì¹˜ ì ˆëŒ€ ìš°ì„ : ë‰´ìŠ¤ ìˆ˜ì¹˜ë¥¼ ìµœìš°ì„  íŒ©íŠ¸ë¡œ ì‚¼ëŠ”ë‹¤.\n"
        "2. ì—°ì†ì„± ì›ì¹™: ê³¼ê±° ë¶„ì„ ê¸°ë¡ê³¼ í˜„ì¬ ì§€í‘œë¥¼ ë¹„êµí•˜ì—¬ ì „ë§ì˜ ì ì¤‘ ì—¬ë¶€ë¥¼ ì–¸ê¸‰í•˜ë¼.\n"
        "3. ì „ëµì  ìˆ˜ì •: ë³€í™”ì— ë”°ë¼ í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘ì„ ìœ ì—°í•˜ê²Œ ì—…ë°ì´íŠ¸í•˜ë¼.\n"
    )

    final_prompt = f"í˜„ì¬ ì„ë¬´: {report_label} íˆ¬ì ì „ëµ ë³´ê³ ì„œ ì‘ì„±\n\në‹¹ì‹ ì€ {base_prompt}\n\n{analysis_guideline}"

    # 2. AI ëª¨ë¸ ì„¤ì • ë° í˜¸ì¶œ (Gemini/OpenAI ë¶„ê¸° ë¡œì§)
    a_cfg = config_data.get("analyst_model", {})
    model_name = a_cfg.get("name")
    print(f"ğŸ¤– [STEP 3] AI ëª¨ë¸ í˜¸ì¶œ: {model_name}")



def _execute_report_ai_engine(config_data, r_type, report_label, input_content):
    """
    [AI ë¶„ì„ ì‹¤í–‰ ì—”ì§„] ì§€ì¹¨ êµ¬ì„±, ëª¨ë¸ í˜¸ì¶œ, ê²°ê³¼ ì €ì¥ í”„ë¡œì„¸ìŠ¤ë¥¼ í†µí•© ê´€ë¦¬í•©ë‹ˆë‹¤.
    """
    now_kst = get_now_kst()
    now_str = now_kst.strftime("%Y-%m-%d %H:%M")
    
    # ğŸ¯ STEP 1: ê³¼ê±° ë§¥ë½ ë° ì„¤ì • ë¡œë“œ
    historical_context = load_historical_contexts()
    a_cfg = config_data.get("analyst_model", {})
    base_url = a_cfg.get("url", "").rstrip('/')
    model_name = a_cfg.get("name")
    
    print(f"ğŸ¤– [STEP 3] AI ëª¨ë¸ í˜¸ì¶œ ì‹œë„: {model_name} (ìœ í˜•: {report_label})")

    # ğŸ¯ STEP 2: ë¦¬í¬íŠ¸ íƒ€ì…ì— ë”°ë¥¸ ë§ì¶¤í˜• í˜ë¥´ì†Œë‚˜(Base Prompt) ì„¤ì •
    if r_type == "daily":
        # ì¼ê°„ ë³´ê³ ì„œëŠ” ì„¤ì •íŒŒì¼ì˜ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        base_prompt = config_data.get("council_prompt", "ë‹¹ì‹ ì€ ì „ë¬¸ ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤.")
    elif r_type in ["weekly", "monthly"]:
        # ì£¼ê°„/ì›”ê°„ì€ ì „ëµ ìì‚° ë°°ë¶„ê°€ ê´€ì ì˜ ê±°ì‹œì  ì§€ì¹¨ ë¶€ì—¬
        base_prompt = (
            f"ë‹¹ì‹ ì€ 'ì „ëµ ìì‚° ë°°ë¶„ê°€'ì…ë‹ˆë‹¤. ì œê³µëœ {r_type} ì§€í‘œ ì¶”ì„¸ì™€ ê³¼ê±° ë¶„ì„ ê¸°ë¡ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ "
            "ë‹¨ê¸°ì  ì†ŒìŒ(Noise)ì„ ì œê±°í•˜ê³  ê±°ì‹œì ì¸ íë¦„(Trend)ì„ ìš”ì•½í•˜ì„¸ìš”. "
            "í–¥í›„ ëŒ€ì‘ ì „ëµê³¼ í¬íŠ¸í´ë¦¬ì˜¤ ì¡°ì • ë°©í–¥ì— ì§‘ì¤‘í•˜ì—¬ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”."
        )
    else:
        base_prompt = config_data.get("council_prompt", "ë‹¹ì‹ ì€ ì „ë¬¸ ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤.")

    # ğŸ¯ STEP 3: ë¶„ì„ ê°€ì´ë“œë¼ì¸ ë° ì¶œë ¥ êµ¬ì¡° ì •ì˜
    analysis_guideline = (
        "### [ ìë£Œ ë¶„ì„ ì§€ì¹¨ ]\n"                        
        "1. ì‹œì¥ ìƒíƒœ ì¸ì§€: í˜„ì¬ê°€ ì£¼ë§ì´ë©´ ê°€ì¥ ìµœê·¼ ê±°ë˜ì¼(ê¸ˆìš”ì¼) ì¢…ê°€ë¥¼ í˜„ì¬ê°€ë¡œ ê°„ì£¼í•œë‹¤.\n"
        "2. ìˆ˜ì¹˜ ì ˆëŒ€ ìš°ì„ : ë‰´ìŠ¤ ì œëª©ì˜ í†¤ë³´ë‹¤ 'ì›ì²œ ìˆ˜ê¸‰ ì§€í‘œ'ì˜ ë“±ë½ ìˆ˜ì¹˜(+0.55% ë“±)ë¥¼ ìµœìš°ì„  íŒ©íŠ¸ë¡œ ì‚¼ëŠ”ë‹¤.\n"
        "3. ì¶”ì„¸ì™€ ë°˜ë“± êµ¬ë¶„: ë©°ì¹ ê°„ í•˜ë½í–ˆë”ë¼ë„ ë§ˆì§€ë§‰ ì§€í‘œê°€ ìƒìŠ¹ì´ë©´ 'ë‹¨ê¸° ë°˜ë“± ì„±ê³µ'ìœ¼ë¡œ í•´ì„í•˜ë¼.\n"
        "4. ì—°ì†ì„± ì›ì¹™: 'ê³¼ê±° ë¶„ì„ ê¸°ë¡'ì—ì„œ ì œì‹œí–ˆë˜ ì£¼ìš” ì „ë§ê³¼ ì˜¤ëŠ˜ 'ì›ì²œ ìˆ˜ê¸‰ ì§€í‘œ'ë¥¼ ë¹„êµí•˜ì—¬ ì˜ˆì¸¡ ì ì¤‘ ì—¬ë¶€ë¥¼ ë°˜ë“œì‹œ ì–¸ê¸‰í•˜ë¼.\n"
        "5. ì „ëµì  ìˆ˜ì •: ì§€í‘œ ë³€í™”ì— ë”°ë¼ í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘ì´ë‚˜ íˆ¬ì í–‰ë™ ì§€ì¹¨ì„ ìœ ì—°í•˜ê²Œ ì—…ë°ì´íŠ¸í•˜ë¼.\n"
        "6. ë‰´ìŠ¤ì •ë¦¬: ë‰´ìŠ¤ê°€ ê±°ì‹œê²½ì œë‚˜ ìœ ë™ì„±ì— ì¤‘ìš”í•œì§€ íŒë…í•˜ì—¬ ê°€ì¤‘ì¹˜ë¥¼ ë‘”ë‹¤.\n"
    )

    structure_instruction = (
        "### [ ë³´ê³ ì„œ ì‘ì„± í˜•ì‹ ]\n"
        "ì•„ë˜ êµ¬ì¡°ë¥¼ ë°˜ë“œì‹œ ì—„ìˆ˜í•˜ì—¬ ì‘ì„±í•˜ë¼:\n"
        "1. ì‹œí™© ë¸Œë¦¬í•‘ / 2. ì£¼ìš” ë‰´ìŠ¤ ë° ì˜¤í”¼ë‹ˆì–¸ / 3. ê±°ì‹œê²½ì œ ë¶„ì„ / 4. ìì‚°ë³„ ë¶„ì„ / 5. ì‚°ì—…ë³„ ë¶„ì„ / "
        "6. ì£¼ë ¥/ë¯¸ë˜ ì‚°ì—… ì „ë§ / 7. ë¦¬ìŠ¤í¬ ë¶„ì„ / 8. í¬íŠ¸í´ë¦¬ì˜¤ ë° ì „ëµ(ë¹„ì¤‘ % í¬í•¨) / 8. ë‰´ìŠ¤ì—ì„œ ìˆ˜ì§‘í•œ ê²½ì œì§€í‘œë“¤(ë‹¤ìŒ ë³´ê³ ì„œë¥¼ ìœ„í•œ)\n"
    )

    # ğŸ¯ STEP 4: ìµœì¢… í”„ë¡¬í”„íŠ¸ í†µí•©
    final_prompt = (
        f"í˜„ì¬ ì„ë¬´: {report_label} íˆ¬ì ì „ëµ ë³´ê³ ì„œ ì‘ì„±\n\n"
        f"ë‹¹ì‹ ì€ {base_prompt}\n\n"
        f"{analysis_guideline}\n"
        f"{structure_instruction}\n"
        f"ìœ„ 'ì›ì²œ ìˆ˜ê¸‰ ì§€í‘œ'ì˜ ìˆ˜ì¹˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‰´ìŠ¤ë¥¼ í•´ì„í•˜ê³  ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ë¼."
    )

    # ğŸ¯ STEP 5: API ì¸ì¦ ì •ë³´ ë¡œë“œ (config ê°ì²´ ì°¸ì¡°)
    oa_key = config.get("openai_api_key", "")
    gm_key = config.get("gemini_api_key", "")

    # ğŸ¯ STEP 6: ëª¨ë¸ ìœ í˜•ë³„ í˜ì´ë¡œë“œ êµ¬ì„± ë° í˜¸ì¶œ
    if "googleapis.com" in base_url or "gemini" in model_name.lower():
        # Gemini API í˜¸ì¶œ ë°©ì‹
        url = f"{base_url}/v1beta/models/{model_name}:generateContent?key={gm_key}"
        headers = {"Content-Type": "application/json"}
        payload = {
            "contents": [{
                "parts": [{"text": f"ì§€ì¹¨: {final_prompt}\n\nê³¼ê±°ë§¥ë½: {historical_context}\në°ì´í„°:\n{input_content}"}]
            }]
        }
    else:
        # OpenAI ìŠ¤íƒ€ì¼ API í˜¸ì¶œ ë°©ì‹ (GPT ë° í˜¸í™˜ ëª¨ë¸)
        url = f"{base_url}/chat/completions"
        headers = {"Content-Type": "application/json"}
        if oa_key and ("gpt" in model_name.lower() or "openai" in base_url.lower()):
            headers["Authorization"] = f"Bearer {oa_key}"
        
        payload = {
            "model": model_name,
            "messages": [
                {"role": "system", "content": f"ê¸°ì¤€ì‹œê°: {now_str}\n{final_prompt}\n{historical_context}"},
                {"role": "user", "content": input_content}
            ],
            "temperature": a_cfg.get("temperature", 0.3)
        }

    # ğŸ¯ STEP 7: ìš”ì²­ ì‹¤í–‰ ë° ê²°ê³¼ ì²˜ë¦¬
    try:
        start_time = time.time()
        resp = requests.post(url, json=payload, headers=headers, timeout=300)
        resp.raise_for_status()
        result = resp.json()
        duration = time.time() - start_time
        
        # ì‘ë‹µ êµ¬ì¡° íŒŒì‹±
        if "candidates" in result:
            report_content = result['candidates'][0]['content']['parts'][0]['text']
        else:
            report_content = result['choices'][0]['message']['content']
        
        # ê²°ê³¼ íŒŒì¼ ì €ì¥
        save_path = save_report_to_file(report_content, r_type)
        print(f"âœ¨ [STEP 4] {report_label} ì‘ë‹µ ìˆ˜ì‹  ì„±ê³µ! (ì†Œìš”ì‹œê°„: {duration:.1f}ì´ˆ)")
        print(f"ğŸ’¾ [STEP 5] ë³´ê³ ì„œ ì €ì¥ ì™„ë£Œ: {save_path}")
        return True

    except Exception as e:
        print(f"ğŸš¨ [ì—ëŸ¬] AI ì—”ì§„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ({r_type}): {e}")
        return False


if __name__ == "__main__":
    last_news_time = 0
    last_auto_report_date = ""
    last_weekly_report_date = "" 
    last_monthly_report_date = ""

# ì‹œìŠ¤í…œ ì‹œì‘ ë¡œê·¸ (ì´ˆê¸° ì„¤ì • ë¡œë“œ)
    try:
        init_config = load_data()
        report_time = init_config.get('report_gen_time', '08:00')
        print(f"ğŸš€ [AI Analyst] ì‹œìŠ¤í…œ ê°€ë™ - ê¸°ì¤€ ì‹œê°: {report_time} (KST)")
        print(f"ğŸ“‚ ì €ì¥ ê²½ë¡œ: {BASE_PATH} | ë‰´ìŠ¤ ëŒ€ê¸°ì—´: {PENDING_PATH}")
    except Exception as e:
        print(f"âŒ ì´ˆê¸° ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")

    while True:
        try:
            # 1. ë§¤ ë£¨í”„ë§ˆë‹¤ ìµœì‹  ì„¤ì • ë° ì‹œê° ì—…ë°ì´íŠ¸
            now_kst = get_now_kst()
            current_config = load_data()
            auto_gen_enabled = current_config.get("report_auto_gen", False)
            
            # ì‹¤í–‰ ê¸°ì¤€ ì‹œê° ì„¤ì • (ë¬¸ìì—´ ê³µë°± ì œê±°)
            base_time_str = str(current_config.get("report_gen_time", "08:00")).strip()
            current_time_str = now_kst.strftime("%H:%M")
            
            # 2. ì‹¤í–‰ ì‹œê° ê³„ì‚° (ì£¼ê°„/ì›”ê°„ì€ ìˆœì°¨ ì²˜ë¦¬ë¥¼ ìœ„í•´ 10~20ë¶„ ê°„ê²© ë°°ì¹˜)
            base_dt = datetime.strptime(base_time_str, "%H:%M")
            weekly_time_str = (base_dt + timedelta(minutes=10)).strftime("%H:%M")
            monthly_time_str = (base_dt + timedelta(minutes=20)).strftime("%H:%M")

            # --- [ ğŸ¤– ìë™ ë³´ê³ ì„œ ìƒì„± ì„¹ì…˜ ] ---
            if auto_gen_enabled:
                
                # â‘  ì¼ê°„ ë³´ê³ ì„œ (ë§¤ì¼ ì§€ì • ì‹œê°)
                if current_time_str == base_time_str:
                    today_str = now_kst.strftime("%Y-%m-%d")
                    if last_auto_report_date != today_str:
                        print(f"ğŸ¤– [{now_kst.strftime('%H:%M:%S')}] >>> (1/3) ì¼ê°„ ë³´ê³ ì„œ ìƒì„± ì‹œí€€ìŠ¤ ì§„ì…")
                        if generate_auto_report(current_config, r_type="daily"):
                            last_auto_report_date = today_str

                # â‘¡ ì£¼ê°„ ë³´ê³ ì„œ (ì¼ìš”ì¼ & ì§€ì • ì‹œê° + 10ë¶„)
                elif current_time_str == weekly_time_str and now_kst.weekday() == 6:
                    week_str = now_kst.strftime("%Y-%U")
                    if last_weekly_report_date != week_str:
                        print(f"ğŸ“… [{now_kst.strftime('%H:%M:%S')}] >>> (2/3) ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ì‹œí€€ìŠ¤ ì§„ì…")
                        if generate_auto_report(current_config, r_type="weekly"):
                            last_weekly_report_date = week_str

                # â‘¢ ì›”ê°„ ë³´ê³ ì„œ (ë§¤ì›” 1ì¼ & ì§€ì • ì‹œê° + 20ë¶„)
                elif current_time_str == monthly_time_str and now_kst.day == 1:
                    month_str = now_kst.strftime("%Y-%m")
                    if last_monthly_report_date != month_str:
                        print(f"ğŸ›ï¸ [{now_kst.strftime('%H:%M:%S')}] >>> (3/3) ì›”ê°„ ë³´ê³ ì„œ ìƒì„± ì‹œí€€ìŠ¤ ì§„ì…")
                        if generate_auto_report(current_config, r_type="monthly"):
                            last_monthly_report_date = month_str

            # --- [ ë‰´ìŠ¤ ìˆ˜ì§‘ ì„¹ì…˜ ] ---
            update_interval_min = current_config.get("update_interval", 10)
            update_interval_sec = update_interval_min * 60
            
            # ë‹¤ìŒ ìˆ˜ì§‘ê¹Œì§€ ë‚¨ì€ ì‹œê°„ ê³„ì‚° (ë¡œê·¸ìš©)
            time_since_last = current_ts - last_news_time
            next_in = max(0, update_interval_sec - time_since_last)

            if time_since_last >= update_interval_sec:
                print(f"ğŸ“¡ [{now_kst.strftime('%H:%M:%S')}] ë‰´ìŠ¤ ìˆ˜ì§‘ ì—”ì§„ ê°€ë™ (ì£¼ê¸°: {update_interval_min}ë¶„)")
                
                feeds = current_config.get("feeds", [])
                g_inc = [k.strip().lower() for k in current_config.get('global_include', "").split(",") if k.strip()]
                g_exc = [k.strip().lower() for k in current_config.get('global_exclude', "").split(",") if k.strip()]
                
                new_saved = 0
                for feed in feeds:
                    try:
                        parsed = feedparser.parse(feed['url'])
                        l_inc = [k.strip().lower() for k in feed.get('include', "").split(",") if k.strip()]
                        l_exc = [k.strip().lower() for k in feed.get('exclude', "").split(",") if k.strip()]
                        
                        feed_new = 0
                        for entry in parsed.entries[:50]:
                            if not check_logic(entry.title, g_inc, g_exc): continue
                            if not check_logic(entry.title, l_inc, l_exc): continue
                            if save_file(entry, feed['name']):
                                feed_new += 1
                                new_saved += 1
                        if feed_new > 0:
                            print(f"   â””â”€ {feed['name']}: {feed_new}ê°œ ì‹ ê·œ ì €ì¥")
                    except Exception as e:
                        print(f"   â””â”€ âŒ {feed.get('name')} ì˜¤ë¥˜: {e}")
                
                print(f"âœ… [{now_kst.strftime('%H:%M:%S')}] ìˆ˜ì§‘ ì™„ë£Œ (ì´ {new_saved}ê°œ ì‹ ê·œ í™•ë³´)")
                last_news_time = current_ts
            else:
                # ë§¤ ë¶„ë§ˆë‹¤ ì •ê¸° ìƒì¡´ ì‹ ê³  ë¡œê·¸ (ì„ íƒ ì‚¬í•­)
                if now_kst.minute % 5 == 0: # 5ë¶„ë§ˆë‹¤ ì¶œë ¥
                    print(f"ğŸ’¤ [{now_kst.strftime('%H:%M:%S')}] ëŒ€ê¸° ì¤‘... (ë‹¤ìŒ ë‰´ìŠ¤ ìˆ˜ì§‘ê¹Œì§€ {int(next_in/60)}ë¶„ ë‚¨ìŒ)")

        except Exception as e: 
            print(f"ğŸš¨ [{datetime.now().strftime('%H:%M:%S')}] ë£¨í”„ ì¹˜ëª…ì  ì—ëŸ¬: {e}")
            
        time.sleep(60)
















