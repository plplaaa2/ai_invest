import hashlib
from common import *

processed_titles = set()

def save_file(entry, feed_name):
    """ê°œì„ ëœ íƒ€ì„ë¼ì¸ ë³´ì¡´ ì €ì¥ ë°©ì‹ (JSON)"""
    global processed_titles
    
    title = entry.title.strip()
# ğŸ¯ 1. ë°œí–‰ ì‹œê°„ì„ KST(í•œêµ­ í‘œì¤€ì‹œ)ë¡œ ì—„ê²©í•˜ê²Œ ë³€í™˜ [cite: 1, 4]
    if hasattr(entry, 'published_parsed') and entry.published_parsed:
        # UTC ê¸°ë°˜ êµ¬ì¡°ì²´ ì‹œê°„ì„ KST datetime ê°ì²´ë¡œ ë³€í™˜ [cite: 3, 4]
        dt_obj = datetime.fromtimestamp(time.mktime(entry.published_parsed), tz=timezone.utc).astimezone(KST)
    else:
        # ì‹œê°„ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° í˜„ì¬ KST ì‹œê° ì‚¬ìš© 
        dt_obj = get_now_kst()
        
    dt_str = dt_obj.strftime('%Y%m%d_%H%M%S')# íŒŒì¼ëª… ì •ë ¬ìš©
    date_key = dt_obj.strftime('%Y%m%d')     # ì¼ë³„ ì¤‘ë³µ ë¶„ë¦¬ìš©
    pub_dt_str = dt_obj.strftime('%Y-%m-%d %H:%M:%S') # ë°ì´í„° ì €ì¥ìš©
    
    # ğŸ¯ 2. ì¤‘ë³µ ì²´í¬ í‚¤ ê°•í™” (ë‚ ì§œ + ì œëª© 15ì)
    # ì´ì œ ë‚ ì§œê°€ ë‹¤ë¥´ë©´ ê°™ì€ ì œëª©ì´ë¼ë„ ë³„ê°œ ë‰´ìŠ¤ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    clean_key = f"{date_key}_{title.replace(' ', '')[:15]}"
    
    if clean_key in processed_titles:
        return False
    
    # ğŸ¯ 3. íŒŒì¼ëª…ì— ì‹œê°„ ì •ë³´ ì£¼ì… (ì •ë ¬ ìµœì í™”)
    file_hash = hashlib.md5(title.encode()).hexdigest()[:6]
    filename = f"{dt_str}_{file_hash}.json" # JSON í™•ì¥ì ì‚¬ìš©
    filepath = os.path.join(PENDING_PATH, filename)
    
    # ğŸ¯ 4. ë°ì´í„° êµ¬ì¡°í™” (AI ë¶„ì„ìš© ì •ë³´ í™•ì¥)
    news_data = {
        "title": title,
        "pub_dt": pub_dt_str, # [ìˆ˜ì • ì™„ë£Œ]
        "source": feed_name,
        "summary": entry.get('summary', 'ë‚´ìš© ì—†ìŒ'),
        "link": entry.get('link', '')
    }
    
    try:
        os.makedirs(PENDING_PATH, exist_ok=True)
        with open(filepath, "w", encoding='utf-8') as f:
            json.dump(news_data, f, ensure_ascii=False, indent=2)
        processed_titles.add(clean_key)
        return True
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì“°ê¸° ì‹¤íŒ¨: {e}") # ì—ëŸ¬ ë¡œê·¸ë¥¼ ë‚¨ê²¨ì•¼ ê²½ë¡œ ë¬¸ì œë¥¼ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        return False
        
def check_logic(text, inc_list, exc_list):
    """í•„í„°ë§ ë¡œì§: ì œì™¸ì–´ í¬í•¨ ì‹œ íƒˆë½, í¬í•¨ì–´ ì„¤ì • ì‹œ í¬í•¨ë˜ì–´ì•¼ í†µê³¼"""
    text = text.lower()
    if any(x in text for x in exc_list if x):
        return False
    if inc_list:
        if not any(i in text for i in inc_list if i):
            return False
    return True

def cleanup_old_files(retention_days):
    """ì„¤ì •ëœ ê¸°ê°„ë³´ë‹¤ ì˜¤ë˜ëœ íŒŒì¼ ë° ë©”ëª¨ë¦¬ ìºì‹œ ì‚­ì œ"""
    global processed_titles
    if not os.path.exists(PENDING_PATH): return
    
    current_time = time.time()
    seconds_threshold = retention_days * 86400
    deleted_count = 0
    
    for filename in os.listdir(PENDING_PATH):
        file_path = os.path.join(PENDING_PATH, filename)
        if os.path.isfile(file_path) and (filename.endswith(".json") or filename.endswith(".txt")):
            if (current_time - os.path.getmtime(file_path)) > seconds_threshold:
                try:
                    os.remove(file_path)
                    deleted_count += 1
                except: pass
    
    # íŒŒì¼ ì‚­ì œ ì‹œ ë©”ëª¨ë¦¬ ìºì‹œë„ í•¨ê»˜ ë¹„ì›Œ ì‹œìŠ¤í…œì„ ê°€ë³ê²Œ ìœ ì§€
    processed_titles.clear()
    if deleted_count > 0:
        print(f"ğŸ§¹ {deleted_count}ê°œì˜ ë‰´ìŠ¤ íŒŒì¼ì„ ì •ë¦¬í•˜ê³  ì¤‘ë³µ í•„í„°ë¥¼ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")


def generate_auto_report(config_data, r_type):
    """ìë™ ë³´ê³ ì„œ ìƒì„± ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""
    # 1. ë°ì´í„° ì¤€ë¹„ (common.py í™œìš©)
    input_content, label = prepare_report_data(r_type, config_data)
    
    if not input_content:
        print(f"âš ï¸ [Auto] ë¶„ì„í•  ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ ë³´ê³ ì„œ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return False

    print(f"ğŸ¤– [Auto] {label} ë³´ê³ ì„œ ìƒì„± ì‹œì‘...")
    
    # 2. AI ìƒì„± (common.py í™œìš©)
    report_content = generate_invest_report(r_type, input_content, config_data)
    
    if report_content and "âŒ" not in report_content:
        # 3. ì €ì¥
        save_path = save_report_to_file(report_content, r_type)
        print(f"âœ¨ [Auto] {label} ìƒì„± ì™„ë£Œ! ì €ì¥ë¨: {save_path}")
        return True
    else:
        print(f"ğŸš¨ [Auto] ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {report_content}")
        return False

# --- [ 3. ë©”ì¸ ë£¨í”„ (ìˆ˜ë™ ì‘ì—…ì— ë°©í•´ë°›ì§€ ì•ŠëŠ” ìŠ¤ì¼€ì¤„ëŸ¬) ] ---

if __name__ == "__main__":
    # ğŸ’¡ ìë™í™”(Auto) ì „ìš© ìƒíƒœ ê´€ë¦¬ ë³€ìˆ˜ (ìˆ˜ë™ ì‹¤í–‰ ì‹œ ì´ ë³€ìˆ˜ë“¤ì„ ê±´ë“œë¦¬ì§€ ì•Šìœ¼ë©´ ìë™ ì‹¤í–‰ë¨)
    auto_daily_done_date = ""
    auto_weekly_done_week = ""
    auto_monthly_done_month = ""
    
    last_news_time = 0

    try:
        init_config = load_data()
        print(f"ğŸš€ [AI Analyst] ì‹œìŠ¤í…œ ê°€ë™ - ê¸°ì¤€ ì‹œê°: {init_config.get('report_gen_time', '08:00')} (KST)")
    except Exception as e:
        print(f"âŒ ì´ˆê¸° ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")

    while True:
        try:
            now_kst = get_now_kst()
            current_ts = time.time() # ğŸš¨ NameError í•´ê²°
            current_config = load_data()
            
            auto_gen_enabled = current_config.get("report_auto_gen", False)
            base_time_str = str(current_config.get("report_gen_time", "08:00")).strip()
            current_time_str = now_kst.strftime("%H:%M")
            
            # ì˜ˆì•½ ì‹œê° ê³„ì‚° (10ë¶„/20ë¶„ ê°„ê²©)
            base_dt = datetime.strptime(base_time_str, "%H:%M")
            weekly_time_str = (base_dt + timedelta(minutes=10)).strftime("%H:%M")
            monthly_time_str = (base_dt + timedelta(minutes=20)).strftime("%H:%M")

            # --- [ ğŸ¤– ìë™ ë³´ê³ ì„œ ìƒì„± ì„¹ì…˜ ] ---
            if auto_gen_enabled:
                
                # â‘  ì¼ê°„ ìë™ ë³´ê³ ì„œ
                if current_time_str == base_time_str:
                    today_str = now_kst.strftime("%Y-%m-%d")
                    # ğŸ’¡ ìˆ˜ë™ ë³´ê³ ì„œ íŒŒì¼ì´ ìˆì–´ë„, 'ìë™ ìŠ¤ì¼€ì¤„ëŸ¬'ê°€ ì˜¤ëŠ˜ ì²˜ìŒì´ë¼ë©´ ì‹¤í–‰í•©ë‹ˆë‹¤.
                    if auto_daily_done_date != today_str:
                        print(f"ğŸ¤– [{now_kst.strftime('%H:%M:%S')}] >>> ìŠ¤ì¼€ì¤„ëŸ¬: ìë™ ì¼ê°„ ë³´ê³ ì„œ ìƒì„± ì‹œë„")
                        if generate_auto_report(current_config, "daily"):
                            auto_daily_done_date = today_str # ìë™ ì‹¤í–‰ ì„±ê³µ ì‹œì—ë§Œ ë§ˆí‚¹

                # â‘¡ ì£¼ê°„ ìë™ ë³´ê³ ì„œ (ì¼ìš”ì¼)
                elif current_time_str == weekly_time_str and now_kst.weekday() == 6:
                    week_str = now_kst.strftime("%Y-%U")
                    if auto_weekly_done_week != week_str:
                        print(f"ğŸ“… [{now_kst.strftime('%H:%M:%S')}] >>> ìŠ¤ì¼€ì¤„ëŸ¬: ìë™ ì£¼ê°„ ë³´ê³ ì„œ ìƒì„± ì‹œë„")
                        if generate_auto_report(current_config, "weekly"):
                            auto_weekly_done_week = week_str

                # â‘¢ ì›”ê°„ ìë™ ë³´ê³ ì„œ (1ì¼)
                elif current_time_str == monthly_time_str and now_kst.day == 1:
                    month_str = now_kst.strftime("%Y-%m")
                    if auto_monthly_done_month != month_str:
                        print(f"ğŸ›ï¸ [{now_kst.strftime('%H:%M:%S')}] >>> ìŠ¤ì¼€ì¤„ëŸ¬: ìë™ ì›”ê°„ ë³´ê³ ì„œ ìƒì„± ì‹œë„")
                        if generate_auto_report(current_config, "monthly"):
                            auto_monthly_done_month = month_str
            # --- [ ë‰´ìŠ¤ ìˆ˜ì§‘ ì„¹ì…˜ ] ---
            update_interval_min = current_config.get("update_interval", 10)
            update_interval_sec = update_interval_min * 60
            
            # ë‹¤ìŒ ìˆ˜ì§‘ê¹Œì§€ ë‚¨ì€ ì‹œê°„ ê³„ì‚° (ë¡œê·¸ìš©)
            time_since_last = current_ts - last_news_time
            next_in = max(0, update_interval_sec - time_since_last)

            if time_since_last >= update_interval_sec:
                print(f"ğŸ“¡ [{now_kst.strftime('%H:%M:%S')}] ë‰´ìŠ¤ ìˆ˜ì§‘ ì—”ì§„ ê°€ë™ (ì£¼ê¸°: {update_interval_min}ë¶„)")
                
                feeds = current_config.get("feeds", [])
                g_inc = [k.strip().lower() for k in current_config.get('global_include', "").split(",") if k.strip()]
                g_exc = [k.strip().lower() for k in current_config.get('global_exclude', "").split(",") if k.strip()]
                
                new_saved = 0
                for feed in feeds:
                    try:
                        parsed = feedparser.parse(feed['url'])
                        l_inc = [k.strip().lower() for k in feed.get('include', "").split(",") if k.strip()]
                        l_exc = [k.strip().lower() for k in feed.get('exclude', "").split(",") if k.strip()]
                        
                        feed_new = 0
                        for entry in parsed.entries[:50]:
                            if not check_logic(entry.title, g_inc, g_exc): continue
                            if not check_logic(entry.title, l_inc, l_exc): continue
                            if save_file(entry, feed['name']):
                                feed_new += 1
                                new_saved += 1
                        if feed_new > 0:
                            print(f"   â””â”€ {feed['name']}: {feed_new}ê°œ ì‹ ê·œ ì €ì¥")
                    except Exception as e:
                        print(f"   â””â”€ âŒ {feed.get('name')} ì˜¤ë¥˜: {e}")
                
                print(f"âœ… [{now_kst.strftime('%H:%M:%S')}] ìˆ˜ì§‘ ì™„ë£Œ (ì´ {new_saved}ê°œ ì‹ ê·œ í™•ë³´)")
                last_news_time = current_ts
            else:
                # ë§¤ ë¶„ë§ˆë‹¤ ì •ê¸° ìƒì¡´ ì‹ ê³  ë¡œê·¸ (ì„ íƒ ì‚¬í•­)
                if now_kst.minute % 5 == 0: # 5ë¶„ë§ˆë‹¤ ì¶œë ¥
                    print(f"ğŸ’¤ [{now_kst.strftime('%H:%M:%S')}] ëŒ€ê¸° ì¤‘... (ë‹¤ìŒ ë‰´ìŠ¤ ìˆ˜ì§‘ê¹Œì§€ {int(next_in/60)}ë¶„ ë‚¨ìŒ)")

        except Exception as e: 
            print(f"ğŸš¨ [{datetime.now().strftime('%H:%M:%S')}] ë£¨í”„ ì¹˜ëª…ì  ì—ëŸ¬: {e}")
            
        time.sleep(60)
